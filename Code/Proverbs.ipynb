{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3i_Tut4jo9NZ"
   },
   "outputs": [],
   "source": [
    "# Vous pourriez avoir besoin d'exécuter le code ci dessous en commentaire\n",
    "# si une erreur survient lors de l'exécution du notebook\n",
    "#!pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_g5Jy9XSo9Ng"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string, os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Dw0z5fUIo9Nh"
   },
   "outputs": [],
   "source": [
    "all_reviews = []\n",
    "data = pd.read_csv('english.csv')\n",
    "all_reviews.extend(list(data.text.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmPqCX8xHzCV",
    "outputId": "60c79206-bfaf-41fb-82f2-d53e44f4c36f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2298"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2usP_JFno9Ni"
   },
   "outputs": [],
   "source": [
    "all_reviews = all_reviews[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9O1QX4Ero9Ni",
    "outputId": "161a1c78-658b-43ac-c508-eef28b7bc1b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Yciz5iNo9Nk",
    "outputId": "71d3e775-4eb2-41a6-d9d2-846a1a334572"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a bird in the hand is worth two in the bush',\n",
       " 'a bunch of fives',\n",
       " 'a chain is only as strong as its weakest link',\n",
       " 'a change is as good as a rest',\n",
       " 'a countenance more in sorrow than in anger',\n",
       " 'a daniel come to judgement',\n",
       " 'a diamond in the rough',\n",
       " 'a diamond is forever',\n",
       " 'a different kettle of fish',\n",
       " 'a dish fit for the gods']"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt \n",
    "\n",
    "corpus = [clean_text(x) for x in all_reviews]\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BG1PgIgTo9Nl"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I5x_wWJ9o9Nm"
   },
   "outputs": [],
   "source": [
    "input_seq = []\n",
    "for line in all_reviews:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_seq = token_list[:i+1]\n",
    "        input_seq.append(n_gram_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bxOwEwjho9Nm"
   },
   "outputs": [],
   "source": [
    "def gen_pad_seq(input_seq):\n",
    "    max_sequence_len = max([len(x) for x in input_seq])\n",
    "    input_seq = np.array(pad_sequences(input_seq, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_seq[:,:-1],input_seq[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = gen_pad_seq(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1Wwtvqco9Nm",
    "outputId": "79d7d673-3c3a-450a-ad94-9326022775da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WCQ-s3VvAyg1"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = K.categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = K.pow(2.0, cross_entropy)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSjZCaRLo9Nn",
    "outputId": "1fcfa1e1-4f9a-44f3-a2fb-446b2c7195fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 13, 100)           155300    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 13, 150)           150600    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               100400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 776)               78376     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 776)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1553)              1206681   \n",
      "=================================================================\n",
      "Total params: 1,691,357\n",
      "Trainable params: 1,691,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add((LSTM(150, activation='relu', return_sequences = True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1_m, perplexity])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6SZ-9JAo9No",
    "outputId": "a6d4acd8-1296-4fff-e064-1e452016b281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "73/73 [==============================] - 9s 75ms/step - loss: 7.9652 - accuracy: 0.0671 - f1_m: 0.0000e+00 - perplexity: 163.3758 - val_loss: 6.6768 - val_accuracy: 0.0723 - val_f1_m: 0.0000e+00 - val_perplexity: 165.0733\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 4s 62ms/step - loss: 6.1529 - accuracy: 0.0855 - f1_m: 0.0000e+00 - perplexity: 128.5332 - val_loss: 6.6809 - val_accuracy: 0.0723 - val_f1_m: 0.0000e+00 - val_perplexity: 277.6906\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 5.9668 - accuracy: 0.0668 - f1_m: 0.0000e+00 - perplexity: 115.9521 - val_loss: 6.7032 - val_accuracy: 0.0723 - val_f1_m: 0.0000e+00 - val_perplexity: 506.2223\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 5.7374 - accuracy: 0.0792 - f1_m: 0.0000e+00 - perplexity: 108.3655 - val_loss: 6.8755 - val_accuracy: 0.0723 - val_f1_m: 0.0000e+00 - val_perplexity: 1658.3820\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 5.6345 - accuracy: 0.0722 - f1_m: 0.0000e+00 - perplexity: 102.7527 - val_loss: 6.8943 - val_accuracy: 0.0723 - val_f1_m: 0.0000e+00 - val_perplexity: 1103.0203\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 5.4999 - accuracy: 0.0832 - f1_m: 0.0000e+00 - perplexity: 94.6219 - val_loss: 7.0566 - val_accuracy: 0.0654 - val_f1_m: 0.0000e+00 - val_perplexity: 3751.1997\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 4s 62ms/step - loss: 5.5186 - accuracy: 0.0583 - f1_m: 0.0000e+00 - perplexity: 90.0665 - val_loss: 7.0439 - val_accuracy: 0.0723 - val_f1_m: 0.0000e+00 - val_perplexity: 3454.5515\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 5.4724 - accuracy: 0.0723 - f1_m: 0.0000e+00 - perplexity: 86.8087 - val_loss: 7.1854 - val_accuracy: 0.0671 - val_f1_m: 0.0000e+00 - val_perplexity: 11722.3887\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 5.3164 - accuracy: 0.0844 - f1_m: 0.0000e+00 - perplexity: 79.6104 - val_loss: 7.3976 - val_accuracy: 0.0740 - val_f1_m: 0.0000e+00 - val_perplexity: 37549.4453\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 5.3322 - accuracy: 0.0830 - f1_m: 0.0000e+00 - perplexity: 78.4901 - val_loss: 7.5459 - val_accuracy: 0.0688 - val_f1_m: 0.0000e+00 - val_perplexity: 70413.4219\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 4s 62ms/step - loss: 5.1006 - accuracy: 0.0934 - f1_m: 0.0029 - perplexity: 68.8757 - val_loss: 7.5371 - val_accuracy: 0.0568 - val_f1_m: 0.0000e+00 - val_perplexity: 797327.6875\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 5.0952 - accuracy: 0.0928 - f1_m: 0.0052 - perplexity: 66.6104 - val_loss: 7.7408 - val_accuracy: 0.0654 - val_f1_m: 0.0032 - val_perplexity: 2092846.7500\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.9418 - accuracy: 0.1007 - f1_m: 0.0211 - perplexity: 61.7483 - val_loss: 7.7462 - val_accuracy: 0.0465 - val_f1_m: 0.0000e+00 - val_perplexity: 2058260.8750\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 5.0427 - accuracy: 0.0734 - f1_m: 0.0127 - perplexity: 61.6081 - val_loss: 7.9203 - val_accuracy: 0.0344 - val_f1_m: 0.0000e+00 - val_perplexity: 1324028.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 4.9098 - accuracy: 0.1103 - f1_m: 0.0137 - perplexity: 58.9365 - val_loss: 8.0791 - val_accuracy: 0.0534 - val_f1_m: 0.0243 - val_perplexity: 8199400.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 4.8019 - accuracy: 0.1072 - f1_m: 0.0469 - perplexity: 54.5081 - val_loss: 8.1493 - val_accuracy: 0.0396 - val_f1_m: 0.0154 - val_perplexity: 113851024.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.7813 - accuracy: 0.1005 - f1_m: 0.0313 - perplexity: 52.6445 - val_loss: 8.2974 - val_accuracy: 0.0448 - val_f1_m: 0.0000e+00 - val_perplexity: 38094428.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 4s 62ms/step - loss: 4.7307 - accuracy: 0.0953 - f1_m: 0.0388 - perplexity: 51.0346 - val_loss: 8.6383 - val_accuracy: 0.0499 - val_f1_m: 0.0180 - val_perplexity: 419345504.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 4.7542 - accuracy: 0.1044 - f1_m: 0.0360 - perplexity: 48.6940 - val_loss: 8.5531 - val_accuracy: 0.0413 - val_f1_m: 0.0096 - val_perplexity: 350665152.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 4.6636 - accuracy: 0.1044 - f1_m: 0.0399 - perplexity: 45.9597 - val_loss: 8.7965 - val_accuracy: 0.0241 - val_f1_m: 0.0032 - val_perplexity: 506503872.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 4.5306 - accuracy: 0.1116 - f1_m: 0.0502 - perplexity: 42.7113 - val_loss: 8.8084 - val_accuracy: 0.0465 - val_f1_m: 0.0064 - val_perplexity: 323196352.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.4457 - accuracy: 0.1286 - f1_m: 0.0527 - perplexity: 40.0270 - val_loss: 8.9868 - val_accuracy: 0.0396 - val_f1_m: 0.0242 - val_perplexity: 288699104.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.4950 - accuracy: 0.1206 - f1_m: 0.0566 - perplexity: 39.4947 - val_loss: 9.0910 - val_accuracy: 0.0448 - val_f1_m: 0.0182 - val_perplexity: 428915168.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 4.4277 - accuracy: 0.1295 - f1_m: 0.0641 - perplexity: 38.1358 - val_loss: 9.4048 - val_accuracy: 0.0534 - val_f1_m: 0.0244 - val_perplexity: 2422036480.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.3813 - accuracy: 0.1490 - f1_m: 0.0987 - perplexity: 36.2068 - val_loss: 9.3997 - val_accuracy: 0.0516 - val_f1_m: 0.0243 - val_perplexity: 2095393664.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.2517 - accuracy: 0.1523 - f1_m: 0.1249 - perplexity: 34.3880 - val_loss: 9.6598 - val_accuracy: 0.0361 - val_f1_m: 0.0208 - val_perplexity: 4607101440.0000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 4s 62ms/step - loss: 4.2615 - accuracy: 0.1602 - f1_m: 0.1195 - perplexity: 33.3807 - val_loss: 9.5933 - val_accuracy: 0.0499 - val_f1_m: 0.0269 - val_perplexity: 988580544.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.2956 - accuracy: 0.1449 - f1_m: 0.0983 - perplexity: 32.3816 - val_loss: 9.5579 - val_accuracy: 0.0551 - val_f1_m: 0.0208 - val_perplexity: 479594528.0000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.2123 - accuracy: 0.1598 - f1_m: 0.1327 - perplexity: 31.2176 - val_loss: 9.8143 - val_accuracy: 0.0551 - val_f1_m: 0.0361 - val_perplexity: 1484914048.0000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 4.1347 - accuracy: 0.1753 - f1_m: 0.1643 - perplexity: 30.2019 - val_loss: 9.8731 - val_accuracy: 0.0499 - val_f1_m: 0.0297 - val_perplexity: 1425374592.0000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.0861 - accuracy: 0.1722 - f1_m: 0.1483 - perplexity: 28.6256 - val_loss: 9.9632 - val_accuracy: 0.0585 - val_f1_m: 0.0299 - val_perplexity: 1307230080.0000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 4.0494 - accuracy: 0.1877 - f1_m: 0.1528 - perplexity: 28.0057 - val_loss: 10.0860 - val_accuracy: 0.0499 - val_f1_m: 0.0239 - val_perplexity: 548304704.0000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 4.0103 - accuracy: 0.1695 - f1_m: 0.1468 - perplexity: 26.5761 - val_loss: 10.2429 - val_accuracy: 0.0585 - val_f1_m: 0.0331 - val_perplexity: 1072126208.0000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 4s 62ms/step - loss: 4.0184 - accuracy: 0.1938 - f1_m: 0.1676 - perplexity: 27.2157 - val_loss: 10.3251 - val_accuracy: 0.0551 - val_f1_m: 0.0270 - val_perplexity: 929426112.0000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.9323 - accuracy: 0.1800 - f1_m: 0.1559 - perplexity: 25.5173 - val_loss: 10.4135 - val_accuracy: 0.0516 - val_f1_m: 0.0301 - val_perplexity: 1351897984.0000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.8681 - accuracy: 0.2133 - f1_m: 0.1899 - perplexity: 24.4014 - val_loss: 10.5768 - val_accuracy: 0.0551 - val_f1_m: 0.0270 - val_perplexity: 2022818816.0000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.8661 - accuracy: 0.1959 - f1_m: 0.2033 - perplexity: 24.2705 - val_loss: 10.6471 - val_accuracy: 0.0602 - val_f1_m: 0.0301 - val_perplexity: 745019584.0000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 3.8126 - accuracy: 0.2019 - f1_m: 0.1896 - perplexity: 23.3699 - val_loss: 10.6237 - val_accuracy: 0.0654 - val_f1_m: 0.0301 - val_perplexity: 517423424.0000\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 3.7832 - accuracy: 0.2101 - f1_m: 0.1679 - perplexity: 22.6363 - val_loss: 10.7346 - val_accuracy: 0.0568 - val_f1_m: 0.0270 - val_perplexity: 913471936.0000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.7881 - accuracy: 0.2089 - f1_m: 0.1720 - perplexity: 22.5328 - val_loss: 10.7297 - val_accuracy: 0.0585 - val_f1_m: 0.0328 - val_perplexity: 368961280.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.6498 - accuracy: 0.2201 - f1_m: 0.1904 - perplexity: 21.3490 - val_loss: 10.8204 - val_accuracy: 0.0482 - val_f1_m: 0.0299 - val_perplexity: 463030432.0000\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.6926 - accuracy: 0.2076 - f1_m: 0.1991 - perplexity: 21.2130 - val_loss: 10.9359 - val_accuracy: 0.0602 - val_f1_m: 0.0301 - val_perplexity: 350739584.0000\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 3.7018 - accuracy: 0.2210 - f1_m: 0.1895 - perplexity: 20.6917 - val_loss: 11.1312 - val_accuracy: 0.0585 - val_f1_m: 0.0300 - val_perplexity: 724098752.0000\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 3.5717 - accuracy: 0.2334 - f1_m: 0.2147 - perplexity: 19.4556 - val_loss: 11.0481 - val_accuracy: 0.0516 - val_f1_m: 0.0331 - val_perplexity: 447389344.0000\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 4s 62ms/step - loss: 3.5044 - accuracy: 0.2471 - f1_m: 0.2127 - perplexity: 18.6667 - val_loss: 11.3031 - val_accuracy: 0.0568 - val_f1_m: 0.0330 - val_perplexity: 605514048.0000\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.4555 - accuracy: 0.2537 - f1_m: 0.2166 - perplexity: 17.9260 - val_loss: 11.2628 - val_accuracy: 0.0551 - val_f1_m: 0.0330 - val_perplexity: 795947392.0000\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.4707 - accuracy: 0.2563 - f1_m: 0.2074 - perplexity: 17.9133 - val_loss: 11.3293 - val_accuracy: 0.0551 - val_f1_m: 0.0330 - val_perplexity: 402602720.0000\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.4363 - accuracy: 0.2521 - f1_m: 0.2124 - perplexity: 17.2100 - val_loss: 11.5811 - val_accuracy: 0.0534 - val_f1_m: 0.0329 - val_perplexity: 3516456960.0000\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.4031 - accuracy: 0.2734 - f1_m: 0.2477 - perplexity: 17.6587 - val_loss: 11.5411 - val_accuracy: 0.0448 - val_f1_m: 0.0330 - val_perplexity: 837422272.0000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.3919 - accuracy: 0.2723 - f1_m: 0.2196 - perplexity: 17.1813 - val_loss: 11.5465 - val_accuracy: 0.0465 - val_f1_m: 0.0330 - val_perplexity: 442360256.0000\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.3656 - accuracy: 0.2646 - f1_m: 0.2224 - perplexity: 16.0120 - val_loss: 11.4869 - val_accuracy: 0.0516 - val_f1_m: 0.0329 - val_perplexity: 668554176.0000\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 3.3810 - accuracy: 0.2713 - f1_m: 0.2290 - perplexity: 16.5497 - val_loss: 11.6686 - val_accuracy: 0.0534 - val_f1_m: 0.0327 - val_perplexity: 1323264512.0000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 3.3696 - accuracy: 0.2654 - f1_m: 0.2452 - perplexity: 16.8041 - val_loss: 11.7966 - val_accuracy: 0.0516 - val_f1_m: 0.0331 - val_perplexity: 1234710912.0000\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.2091 - accuracy: 0.2887 - f1_m: 0.2659 - perplexity: 14.8867 - val_loss: 11.7764 - val_accuracy: 0.0551 - val_f1_m: 0.0299 - val_perplexity: 502703712.0000\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 4s 62ms/step - loss: 3.2423 - accuracy: 0.2969 - f1_m: 0.2436 - perplexity: 15.2445 - val_loss: 11.9608 - val_accuracy: 0.0516 - val_f1_m: 0.0301 - val_perplexity: 1052184000.0000\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.2038 - accuracy: 0.2929 - f1_m: 0.2596 - perplexity: 14.5524 - val_loss: 11.9897 - val_accuracy: 0.0465 - val_f1_m: 0.0343 - val_perplexity: 2019966208.0000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.1583 - accuracy: 0.2970 - f1_m: 0.2589 - perplexity: 13.9223 - val_loss: 11.8992 - val_accuracy: 0.0482 - val_f1_m: 0.0298 - val_perplexity: 558134464.0000\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.1400 - accuracy: 0.3035 - f1_m: 0.2632 - perplexity: 13.9954 - val_loss: 12.1846 - val_accuracy: 0.0568 - val_f1_m: 0.0329 - val_perplexity: 2210700800.0000\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 3.0520 - accuracy: 0.3197 - f1_m: 0.2743 - perplexity: 12.9698 - val_loss: 12.2262 - val_accuracy: 0.0516 - val_f1_m: 0.0446 - val_perplexity: 1719708032.0000\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 3.1091 - accuracy: 0.3078 - f1_m: 0.2657 - perplexity: 13.3518 - val_loss: 12.0485 - val_accuracy: 0.0465 - val_f1_m: 0.0333 - val_perplexity: 794841600.0000\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 3.1331 - accuracy: 0.3167 - f1_m: 0.2434 - perplexity: 13.5081 - val_loss: 12.1519 - val_accuracy: 0.0448 - val_f1_m: 0.0386 - val_perplexity: 432141440.0000\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 3.0595 - accuracy: 0.3172 - f1_m: 0.2510 - perplexity: 13.1213 - val_loss: 12.3637 - val_accuracy: 0.0499 - val_f1_m: 0.0355 - val_perplexity: 1148566912.0000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 3.0193 - accuracy: 0.3247 - f1_m: 0.2691 - perplexity: 12.2787 - val_loss: 12.3894 - val_accuracy: 0.0585 - val_f1_m: 0.0329 - val_perplexity: 807863744.0000\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.9956 - accuracy: 0.3312 - f1_m: 0.2714 - perplexity: 12.7487 - val_loss: 12.4940 - val_accuracy: 0.0448 - val_f1_m: 0.0387 - val_perplexity: 1395293568.0000\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 3.0056 - accuracy: 0.3132 - f1_m: 0.2696 - perplexity: 12.2626 - val_loss: 12.4816 - val_accuracy: 0.0499 - val_f1_m: 0.0329 - val_perplexity: 464683808.0000\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.8850 - accuracy: 0.3639 - f1_m: 0.2998 - perplexity: 11.4746 - val_loss: 12.5618 - val_accuracy: 0.0568 - val_f1_m: 0.0517 - val_perplexity: 966224448.0000\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 2.8915 - accuracy: 0.3494 - f1_m: 0.2944 - perplexity: 11.4342 - val_loss: 12.6143 - val_accuracy: 0.0482 - val_f1_m: 0.0328 - val_perplexity: 640948352.0000\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 2.8358 - accuracy: 0.3675 - f1_m: 0.3249 - perplexity: 11.8539 - val_loss: 12.7363 - val_accuracy: 0.0568 - val_f1_m: 0.0435 - val_perplexity: 1713280384.0000\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.8704 - accuracy: 0.3536 - f1_m: 0.2984 - perplexity: 11.3650 - val_loss: 12.6092 - val_accuracy: 0.0551 - val_f1_m: 0.0444 - val_perplexity: 689747136.0000\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.7909 - accuracy: 0.3675 - f1_m: 0.2967 - perplexity: 10.8821 - val_loss: 12.5725 - val_accuracy: 0.0585 - val_f1_m: 0.0446 - val_perplexity: 480732576.0000\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 2.7647 - accuracy: 0.3690 - f1_m: 0.3278 - perplexity: 10.7546 - val_loss: 12.7923 - val_accuracy: 0.0620 - val_f1_m: 0.0531 - val_perplexity: 554974528.0000\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.7818 - accuracy: 0.3710 - f1_m: 0.3071 - perplexity: 10.4453 - val_loss: 12.8011 - val_accuracy: 0.0516 - val_f1_m: 0.0479 - val_perplexity: 1908032512.0000\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.7461 - accuracy: 0.3819 - f1_m: 0.3041 - perplexity: 10.1497 - val_loss: 12.6551 - val_accuracy: 0.0585 - val_f1_m: 0.0565 - val_perplexity: 438007424.0000\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.7362 - accuracy: 0.3758 - f1_m: 0.3167 - perplexity: 10.0586 - val_loss: 12.8623 - val_accuracy: 0.0585 - val_f1_m: 0.0439 - val_perplexity: 3680124928.0000\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.7170 - accuracy: 0.3826 - f1_m: 0.3188 - perplexity: 9.8494 - val_loss: 13.0128 - val_accuracy: 0.0620 - val_f1_m: 0.0544 - val_perplexity: 1542568064.0000\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.7135 - accuracy: 0.3917 - f1_m: 0.3108 - perplexity: 9.7592 - val_loss: 13.0246 - val_accuracy: 0.0620 - val_f1_m: 0.0408 - val_perplexity: 2688110848.0000\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 2.6594 - accuracy: 0.4101 - f1_m: 0.3290 - perplexity: 9.6402 - val_loss: 12.9815 - val_accuracy: 0.0534 - val_f1_m: 0.0383 - val_perplexity: 2208214784.0000\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.5921 - accuracy: 0.4067 - f1_m: 0.3352 - perplexity: 9.5111 - val_loss: 12.9812 - val_accuracy: 0.0620 - val_f1_m: 0.0586 - val_perplexity: 763222528.0000\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.6389 - accuracy: 0.4044 - f1_m: 0.3123 - perplexity: 9.3990 - val_loss: 13.1607 - val_accuracy: 0.0620 - val_f1_m: 0.0544 - val_perplexity: 2625836544.0000\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.5300 - accuracy: 0.4154 - f1_m: 0.3326 - perplexity: 8.5332 - val_loss: 13.1805 - val_accuracy: 0.0516 - val_f1_m: 0.0537 - val_perplexity: 3257433856.0000\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.5077 - accuracy: 0.4472 - f1_m: 0.3605 - perplexity: 8.8112 - val_loss: 13.1663 - val_accuracy: 0.0602 - val_f1_m: 0.0600 - val_perplexity: 1641927552.0000\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 5s 62ms/step - loss: 2.4478 - accuracy: 0.4445 - f1_m: 0.3652 - perplexity: 8.2466 - val_loss: 13.1140 - val_accuracy: 0.0654 - val_f1_m: 0.0649 - val_perplexity: 2363836160.0000\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.4919 - accuracy: 0.4529 - f1_m: 0.3611 - perplexity: 8.7938 - val_loss: 13.1211 - val_accuracy: 0.0637 - val_f1_m: 0.0589 - val_perplexity: 3761681408.0000\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.4707 - accuracy: 0.4474 - f1_m: 0.3680 - perplexity: 8.3537 - val_loss: 13.1802 - val_accuracy: 0.0620 - val_f1_m: 0.0595 - val_perplexity: 3891265024.0000\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.4432 - accuracy: 0.4489 - f1_m: 0.3774 - perplexity: 8.6790 - val_loss: 13.2615 - val_accuracy: 0.0620 - val_f1_m: 0.0595 - val_perplexity: 5800910336.0000\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.4195 - accuracy: 0.4454 - f1_m: 0.3690 - perplexity: 8.7288 - val_loss: 13.1807 - val_accuracy: 0.0602 - val_f1_m: 0.0599 - val_perplexity: 2863644928.0000\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.4203 - accuracy: 0.4522 - f1_m: 0.3746 - perplexity: 8.4325 - val_loss: 13.2523 - val_accuracy: 0.0637 - val_f1_m: 0.0653 - val_perplexity: 5266092544.0000\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.3700 - accuracy: 0.4660 - f1_m: 0.3841 - perplexity: 8.3083 - val_loss: 13.5430 - val_accuracy: 0.0654 - val_f1_m: 0.0608 - val_perplexity: 7972678144.0000\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 2.3262 - accuracy: 0.4731 - f1_m: 0.4000 - perplexity: 7.5334 - val_loss: 13.3959 - val_accuracy: 0.0775 - val_f1_m: 0.0643 - val_perplexity: 29655128064.0000\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 2.3142 - accuracy: 0.4705 - f1_m: 0.3825 - perplexity: 7.5505 - val_loss: 13.4979 - val_accuracy: 0.0688 - val_f1_m: 0.0628 - val_perplexity: 34089107456.0000\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.3343 - accuracy: 0.4663 - f1_m: 0.3781 - perplexity: 7.5772 - val_loss: 13.4047 - val_accuracy: 0.0740 - val_f1_m: 0.0651 - val_perplexity: 15272315904.0000\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.3954 - accuracy: 0.4454 - f1_m: 0.3654 - perplexity: 8.0098 - val_loss: 13.4144 - val_accuracy: 0.0551 - val_f1_m: 0.0585 - val_perplexity: 26955157504.0000\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.2909 - accuracy: 0.4745 - f1_m: 0.3908 - perplexity: 7.3675 - val_loss: 13.4444 - val_accuracy: 0.0620 - val_f1_m: 0.0656 - val_perplexity: 17853138944.0000\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.2499 - accuracy: 0.5068 - f1_m: 0.3939 - perplexity: 6.9317 - val_loss: 13.5549 - val_accuracy: 0.0723 - val_f1_m: 0.0657 - val_perplexity: 31535925248.0000\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 2.2463 - accuracy: 0.4832 - f1_m: 0.4003 - perplexity: 7.1744 - val_loss: 13.3321 - val_accuracy: 0.0671 - val_f1_m: 0.0584 - val_perplexity: 34131361792.0000\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.1966 - accuracy: 0.5016 - f1_m: 0.3997 - perplexity: 6.6894 - val_loss: 13.4123 - val_accuracy: 0.0706 - val_f1_m: 0.0633 - val_perplexity: 231747387392.0000\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.2267 - accuracy: 0.4917 - f1_m: 0.4190 - perplexity: 7.0789 - val_loss: 13.5947 - val_accuracy: 0.0637 - val_f1_m: 0.0638 - val_perplexity: 69838618624.0000\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.2126 - accuracy: 0.5008 - f1_m: 0.4146 - perplexity: 6.8719 - val_loss: 13.5683 - val_accuracy: 0.0688 - val_f1_m: 0.0725 - val_perplexity: 239272067072.0000\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.1797 - accuracy: 0.5175 - f1_m: 0.4205 - perplexity: 6.7848 - val_loss: 13.6892 - val_accuracy: 0.0723 - val_f1_m: 0.0741 - val_perplexity: 251036303360.0000\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.0900 - accuracy: 0.5297 - f1_m: 0.4427 - perplexity: 6.3726 - val_loss: 13.6488 - val_accuracy: 0.0706 - val_f1_m: 0.0567 - val_perplexity: 38966722560.0000\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 2.0586 - accuracy: 0.5431 - f1_m: 0.4380 - perplexity: 6.2272 - val_loss: 13.5204 - val_accuracy: 0.0671 - val_f1_m: 0.0651 - val_perplexity: 107891212288.0000\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.1036 - accuracy: 0.5149 - f1_m: 0.4311 - perplexity: 6.2824 - val_loss: 13.7537 - val_accuracy: 0.0654 - val_f1_m: 0.0658 - val_perplexity: 194292367360.0000\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.1215 - accuracy: 0.5131 - f1_m: 0.4306 - perplexity: 7.1896 - val_loss: 13.6918 - val_accuracy: 0.0671 - val_f1_m: 0.0632 - val_perplexity: 1301796749312.0000\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.0257 - accuracy: 0.5579 - f1_m: 0.4423 - perplexity: 5.7427 - val_loss: 13.8210 - val_accuracy: 0.0637 - val_f1_m: 0.0665 - val_perplexity: 2654980276224.0000\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.0911 - accuracy: 0.5228 - f1_m: 0.4458 - perplexity: 6.5138 - val_loss: 13.8695 - val_accuracy: 0.0654 - val_f1_m: 0.0646 - val_perplexity: 335613952000.0000\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.0430 - accuracy: 0.5356 - f1_m: 0.4484 - perplexity: 5.9916 - val_loss: 13.8700 - val_accuracy: 0.0723 - val_f1_m: 0.0761 - val_perplexity: 299401379840.0000\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.0051 - accuracy: 0.5432 - f1_m: 0.4647 - perplexity: 5.8345 - val_loss: 13.8364 - val_accuracy: 0.0809 - val_f1_m: 0.0680 - val_perplexity: 646893076480.0000\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.0352 - accuracy: 0.5466 - f1_m: 0.4354 - perplexity: 5.8150 - val_loss: 13.8629 - val_accuracy: 0.0809 - val_f1_m: 0.0675 - val_perplexity: 282159448064.0000\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.9443 - accuracy: 0.5822 - f1_m: 0.4967 - perplexity: 6.3262 - val_loss: 13.9089 - val_accuracy: 0.0706 - val_f1_m: 0.0632 - val_perplexity: 2231053058048.0000\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.9509 - accuracy: 0.5496 - f1_m: 0.4798 - perplexity: 5.8302 - val_loss: 13.9592 - val_accuracy: 0.0706 - val_f1_m: 0.0730 - val_perplexity: 220020654080.0000\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 2.0001 - accuracy: 0.5411 - f1_m: 0.4674 - perplexity: 6.2156 - val_loss: 13.8834 - val_accuracy: 0.0740 - val_f1_m: 0.0642 - val_perplexity: 665479479296.0000\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.9389 - accuracy: 0.5678 - f1_m: 0.4870 - perplexity: 5.6079 - val_loss: 13.9847 - val_accuracy: 0.0757 - val_f1_m: 0.0673 - val_perplexity: 2180284547072.0000\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.9133 - accuracy: 0.5722 - f1_m: 0.5060 - perplexity: 5.6374 - val_loss: 14.0647 - val_accuracy: 0.0706 - val_f1_m: 0.0684 - val_perplexity: 4560719446016.0000\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.9497 - accuracy: 0.5657 - f1_m: 0.4818 - perplexity: 5.7536 - val_loss: 14.1786 - val_accuracy: 0.0757 - val_f1_m: 0.0684 - val_perplexity: 7080424505344.0000\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.8409 - accuracy: 0.5879 - f1_m: 0.5200 - perplexity: 5.3782 - val_loss: 14.0204 - val_accuracy: 0.0826 - val_f1_m: 0.0701 - val_perplexity: 7643174797312.0000\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.8758 - accuracy: 0.5884 - f1_m: 0.5108 - perplexity: 5.5076 - val_loss: 14.1476 - val_accuracy: 0.0757 - val_f1_m: 0.0753 - val_perplexity: 13983120621568.0000\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.8166 - accuracy: 0.5959 - f1_m: 0.5050 - perplexity: 5.2152 - val_loss: 13.9460 - val_accuracy: 0.0671 - val_f1_m: 0.0727 - val_perplexity: 3244361515008.0000\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.8153 - accuracy: 0.5874 - f1_m: 0.5215 - perplexity: 5.0819 - val_loss: 13.9997 - val_accuracy: 0.0723 - val_f1_m: 0.0697 - val_perplexity: 45255512555520.0000\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.8326 - accuracy: 0.5957 - f1_m: 0.5124 - perplexity: 5.9385 - val_loss: 14.1970 - val_accuracy: 0.0688 - val_f1_m: 0.0680 - val_perplexity: 33743997763584.0000\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 1.7791 - accuracy: 0.6085 - f1_m: 0.5285 - perplexity: 4.9440 - val_loss: 14.2028 - val_accuracy: 0.0654 - val_f1_m: 0.0657 - val_perplexity: 12066737881088.0000\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 1.8519 - accuracy: 0.5824 - f1_m: 0.5149 - perplexity: 5.4224 - val_loss: 14.1347 - val_accuracy: 0.0654 - val_f1_m: 0.0623 - val_perplexity: 3243188944896.0000\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.7845 - accuracy: 0.6204 - f1_m: 0.5383 - perplexity: 5.2769 - val_loss: 14.1729 - val_accuracy: 0.0775 - val_f1_m: 0.0704 - val_perplexity: 2852363960320.0000\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.7847 - accuracy: 0.6094 - f1_m: 0.5490 - perplexity: 5.3491 - val_loss: 14.2472 - val_accuracy: 0.0706 - val_f1_m: 0.0670 - val_perplexity: 6673770479616.0000\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.7810 - accuracy: 0.6183 - f1_m: 0.5235 - perplexity: 5.5372 - val_loss: 14.2880 - val_accuracy: 0.0740 - val_f1_m: 0.0680 - val_perplexity: 142244552114176.0000\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.6548 - accuracy: 0.6385 - f1_m: 0.5789 - perplexity: 4.6935 - val_loss: 14.2536 - val_accuracy: 0.0723 - val_f1_m: 0.0660 - val_perplexity: 58895129116672.0000\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.7207 - accuracy: 0.6121 - f1_m: 0.5489 - perplexity: 4.9920 - val_loss: 14.2214 - val_accuracy: 0.0706 - val_f1_m: 0.0655 - val_perplexity: 33502533779456.0000\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.7017 - accuracy: 0.6270 - f1_m: 0.5708 - perplexity: 4.8913 - val_loss: 14.4135 - val_accuracy: 0.0740 - val_f1_m: 0.0623 - val_perplexity: 24282369359872.0000\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.6638 - accuracy: 0.6338 - f1_m: 0.5682 - perplexity: 4.8067 - val_loss: 14.3751 - val_accuracy: 0.0723 - val_f1_m: 0.0657 - val_perplexity: 10478007877632.0000\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.6946 - accuracy: 0.6370 - f1_m: 0.5617 - perplexity: 4.9838 - val_loss: 14.3240 - val_accuracy: 0.0723 - val_f1_m: 0.0677 - val_perplexity: 9938378162176.0000\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.6717 - accuracy: 0.6269 - f1_m: 0.5714 - perplexity: 4.6979 - val_loss: 14.3948 - val_accuracy: 0.0792 - val_f1_m: 0.0762 - val_perplexity: 51745057144832.0000\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.6551 - accuracy: 0.6452 - f1_m: 0.5490 - perplexity: 4.5960 - val_loss: 14.4952 - val_accuracy: 0.0671 - val_f1_m: 0.0751 - val_perplexity: 23613530963968.0000\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.6616 - accuracy: 0.6216 - f1_m: 0.5772 - perplexity: 4.5915 - val_loss: 14.3986 - val_accuracy: 0.0826 - val_f1_m: 0.0738 - val_perplexity: 49433865617408.0000\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.6256 - accuracy: 0.6513 - f1_m: 0.5898 - perplexity: 4.5337 - val_loss: 14.5639 - val_accuracy: 0.0688 - val_f1_m: 0.0696 - val_perplexity: 387206267011072.0000\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.6821 - accuracy: 0.6366 - f1_m: 0.5649 - perplexity: 4.8852 - val_loss: 14.5001 - val_accuracy: 0.0775 - val_f1_m: 0.0804 - val_perplexity: 278932540620800.0000\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.6106 - accuracy: 0.6446 - f1_m: 0.5930 - perplexity: 4.5720 - val_loss: 14.5414 - val_accuracy: 0.0861 - val_f1_m: 0.0690 - val_perplexity: 151876955799552.0000\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.6196 - accuracy: 0.6562 - f1_m: 0.5941 - perplexity: 5.0605 - val_loss: 14.5816 - val_accuracy: 0.0775 - val_f1_m: 0.0679 - val_perplexity: 233825888108544.0000\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.6321 - accuracy: 0.6286 - f1_m: 0.5632 - perplexity: 4.6649 - val_loss: 14.3606 - val_accuracy: 0.0740 - val_f1_m: 0.0678 - val_perplexity: 593487372222464.0000\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.6166 - accuracy: 0.6500 - f1_m: 0.5977 - perplexity: 4.9312 - val_loss: 14.6601 - val_accuracy: 0.0792 - val_f1_m: 0.0708 - val_perplexity: 574487107993600.0000\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.6095 - accuracy: 0.6410 - f1_m: 0.5975 - perplexity: 4.6042 - val_loss: 14.6833 - val_accuracy: 0.0671 - val_f1_m: 0.0717 - val_perplexity: 296558532755456.0000\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.5750 - accuracy: 0.6505 - f1_m: 0.6055 - perplexity: 4.5697 - val_loss: 14.5147 - val_accuracy: 0.0792 - val_f1_m: 0.0729 - val_perplexity: 811806532567040.0000\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.6063 - accuracy: 0.6447 - f1_m: 0.5917 - perplexity: 4.5042 - val_loss: 14.6533 - val_accuracy: 0.0775 - val_f1_m: 0.0760 - val_perplexity: 2282932421001216.0000\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.6040 - accuracy: 0.6619 - f1_m: 0.6016 - perplexity: 5.0026 - val_loss: 14.6123 - val_accuracy: 0.0775 - val_f1_m: 0.0814 - val_perplexity: 705363284328448.0000\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.5658 - accuracy: 0.6750 - f1_m: 0.5982 - perplexity: 4.4252 - val_loss: 14.8269 - val_accuracy: 0.0861 - val_f1_m: 0.0707 - val_perplexity: 1429225932324864.0000\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.5323 - accuracy: 0.6802 - f1_m: 0.6324 - perplexity: 4.6282 - val_loss: 14.7324 - val_accuracy: 0.0792 - val_f1_m: 0.0701 - val_perplexity: 626865173692416.0000\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.5486 - accuracy: 0.6638 - f1_m: 0.6029 - perplexity: 4.4366 - val_loss: 14.6850 - val_accuracy: 0.0723 - val_f1_m: 0.0768 - val_perplexity: 106646797811712.0000\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.5171 - accuracy: 0.6779 - f1_m: 0.6273 - perplexity: 4.4814 - val_loss: 14.5934 - val_accuracy: 0.0878 - val_f1_m: 0.0759 - val_perplexity: 1318691325083648.0000\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.5234 - accuracy: 0.6660 - f1_m: 0.6110 - perplexity: 4.1321 - val_loss: 14.7439 - val_accuracy: 0.0809 - val_f1_m: 0.0695 - val_perplexity: 1510309948817408.0000\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.5223 - accuracy: 0.6677 - f1_m: 0.6262 - perplexity: 4.6595 - val_loss: 14.6261 - val_accuracy: 0.0792 - val_f1_m: 0.0770 - val_perplexity: 343077524865024.0000\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.5206 - accuracy: 0.6639 - f1_m: 0.6249 - perplexity: 4.5888 - val_loss: 14.7325 - val_accuracy: 0.0706 - val_f1_m: 0.0762 - val_perplexity: 1365376680067072.0000\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.4467 - accuracy: 0.6956 - f1_m: 0.6412 - perplexity: 4.2893 - val_loss: 14.8884 - val_accuracy: 0.0706 - val_f1_m: 0.0779 - val_perplexity: 1299342363197440.0000\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.4947 - accuracy: 0.6677 - f1_m: 0.6255 - perplexity: 4.2024 - val_loss: 14.8647 - val_accuracy: 0.0792 - val_f1_m: 0.0752 - val_perplexity: 307989386887168.0000\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 1.4339 - accuracy: 0.6926 - f1_m: 0.6474 - perplexity: 3.9632 - val_loss: 14.8648 - val_accuracy: 0.0826 - val_f1_m: 0.0762 - val_perplexity: 334392966774784.0000\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.4506 - accuracy: 0.6895 - f1_m: 0.6429 - perplexity: 3.8785 - val_loss: 14.7830 - val_accuracy: 0.0740 - val_f1_m: 0.0802 - val_perplexity: 3670946128855040.0000\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.4656 - accuracy: 0.6826 - f1_m: 0.6399 - perplexity: 3.9642 - val_loss: 14.8631 - val_accuracy: 0.0757 - val_f1_m: 0.0736 - val_perplexity: 452772331782144.0000\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.4668 - accuracy: 0.6853 - f1_m: 0.6366 - perplexity: 4.7269 - val_loss: 15.0981 - val_accuracy: 0.0757 - val_f1_m: 0.0764 - val_perplexity: 7533094538051584.0000\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.4186 - accuracy: 0.6927 - f1_m: 0.6525 - perplexity: 3.8607 - val_loss: 15.0353 - val_accuracy: 0.0740 - val_f1_m: 0.0762 - val_perplexity: 1205406999248896.0000\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.4151 - accuracy: 0.6889 - f1_m: 0.6538 - perplexity: 3.9370 - val_loss: 14.9191 - val_accuracy: 0.0826 - val_f1_m: 0.0816 - val_perplexity: 656463403941888.0000\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.4534 - accuracy: 0.6888 - f1_m: 0.6374 - perplexity: 4.0033 - val_loss: 14.9742 - val_accuracy: 0.0843 - val_f1_m: 0.0891 - val_perplexity: 573351223361536.0000\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.4101 - accuracy: 0.7034 - f1_m: 0.6645 - perplexity: 4.2210 - val_loss: 14.8811 - val_accuracy: 0.0826 - val_f1_m: 0.0804 - val_perplexity: 5527437689487360.0000\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.3918 - accuracy: 0.7019 - f1_m: 0.6694 - perplexity: 3.8531 - val_loss: 14.9627 - val_accuracy: 0.0775 - val_f1_m: 0.0815 - val_perplexity: 854968135319552.0000\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.4216 - accuracy: 0.6986 - f1_m: 0.6652 - perplexity: 4.2935 - val_loss: 15.0235 - val_accuracy: 0.0809 - val_f1_m: 0.0771 - val_perplexity: 6703772860416000.0000\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.3668 - accuracy: 0.7193 - f1_m: 0.6710 - perplexity: 4.3528 - val_loss: 14.8253 - val_accuracy: 0.0740 - val_f1_m: 0.0754 - val_perplexity: 161787005632512.0000\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.2981 - accuracy: 0.7276 - f1_m: 0.6921 - perplexity: 3.6484 - val_loss: 14.9837 - val_accuracy: 0.0861 - val_f1_m: 0.0852 - val_perplexity: 53123016032256.0000\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.4140 - accuracy: 0.6892 - f1_m: 0.6581 - perplexity: 4.0857 - val_loss: 15.0258 - val_accuracy: 0.0843 - val_f1_m: 0.0850 - val_perplexity: 580334974402560.0000\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.3798 - accuracy: 0.7111 - f1_m: 0.6719 - perplexity: 4.0694 - val_loss: 15.1156 - val_accuracy: 0.0826 - val_f1_m: 0.0794 - val_perplexity: 952820576550912.0000\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.3174 - accuracy: 0.7306 - f1_m: 0.6892 - perplexity: 3.8180 - val_loss: 15.0599 - val_accuracy: 0.0740 - val_f1_m: 0.0793 - val_perplexity: 546892077334528.0000\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.3428 - accuracy: 0.7120 - f1_m: 0.6846 - perplexity: 3.8639 - val_loss: 15.0512 - val_accuracy: 0.0740 - val_f1_m: 0.0817 - val_perplexity: 333411096985600.0000\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.3278 - accuracy: 0.7231 - f1_m: 0.6753 - perplexity: 3.5524 - val_loss: 15.1415 - val_accuracy: 0.0895 - val_f1_m: 0.0958 - val_perplexity: 780351936921600.0000\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.3422 - accuracy: 0.7045 - f1_m: 0.6808 - perplexity: 3.8145 - val_loss: 15.1623 - val_accuracy: 0.0843 - val_f1_m: 0.0768 - val_perplexity: 50989331644416.0000\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.3070 - accuracy: 0.7222 - f1_m: 0.6794 - perplexity: 3.7149 - val_loss: 15.1347 - val_accuracy: 0.0809 - val_f1_m: 0.0832 - val_perplexity: 871776087179264.0000\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.3600 - accuracy: 0.7010 - f1_m: 0.6737 - perplexity: 3.7440 - val_loss: 15.3546 - val_accuracy: 0.0809 - val_f1_m: 0.0810 - val_perplexity: 2555718142001152.0000\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.3514 - accuracy: 0.6966 - f1_m: 0.6815 - perplexity: 3.8798 - val_loss: 15.3152 - val_accuracy: 0.0826 - val_f1_m: 0.0854 - val_perplexity: 641945474957312.0000\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.3380 - accuracy: 0.7104 - f1_m: 0.6813 - perplexity: 3.7633 - val_loss: 15.2973 - val_accuracy: 0.0792 - val_f1_m: 0.0871 - val_perplexity: 3543844087922688.0000\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.3131 - accuracy: 0.7166 - f1_m: 0.6884 - perplexity: 3.7766 - val_loss: 15.1218 - val_accuracy: 0.0775 - val_f1_m: 0.0719 - val_perplexity: 51228524412928.0000\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.2656 - accuracy: 0.7252 - f1_m: 0.7072 - perplexity: 3.5246 - val_loss: 15.3558 - val_accuracy: 0.0757 - val_f1_m: 0.0782 - val_perplexity: 3594270493638656.0000\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.3344 - accuracy: 0.7240 - f1_m: 0.6847 - perplexity: 3.8688 - val_loss: 15.1722 - val_accuracy: 0.0740 - val_f1_m: 0.0835 - val_perplexity: 622155674943488.0000\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.3258 - accuracy: 0.7012 - f1_m: 0.6747 - perplexity: 3.5774 - val_loss: 15.2519 - val_accuracy: 0.0775 - val_f1_m: 0.0891 - val_perplexity: 754808826888192.0000\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.2610 - accuracy: 0.7418 - f1_m: 0.7068 - perplexity: 3.9974 - val_loss: 15.2178 - val_accuracy: 0.0878 - val_f1_m: 0.0875 - val_perplexity: 682542109818880.0000\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.2295 - accuracy: 0.7450 - f1_m: 0.7275 - perplexity: 3.5264 - val_loss: 15.0416 - val_accuracy: 0.0861 - val_f1_m: 0.0912 - val_perplexity: 414313349120000.0000\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.2478 - accuracy: 0.7378 - f1_m: 0.7065 - perplexity: 3.3443 - val_loss: 15.1887 - val_accuracy: 0.0775 - val_f1_m: 0.0813 - val_perplexity: 2044474897203200.0000\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.2570 - accuracy: 0.7346 - f1_m: 0.7162 - perplexity: 3.8109 - val_loss: 15.2008 - val_accuracy: 0.0723 - val_f1_m: 0.0839 - val_perplexity: 2039324694544384.0000\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.3040 - accuracy: 0.7059 - f1_m: 0.6910 - perplexity: 4.0698 - val_loss: 15.4814 - val_accuracy: 0.0740 - val_f1_m: 0.0783 - val_perplexity: 4128040707686400.0000\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.2764 - accuracy: 0.7200 - f1_m: 0.7191 - perplexity: 3.7210 - val_loss: 15.3033 - val_accuracy: 0.0775 - val_f1_m: 0.0878 - val_perplexity: 1094396120399872.0000\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.2657 - accuracy: 0.7246 - f1_m: 0.7084 - perplexity: 4.0874 - val_loss: 15.3808 - val_accuracy: 0.0792 - val_f1_m: 0.0922 - val_perplexity: 5285593449758720.0000\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.2562 - accuracy: 0.7159 - f1_m: 0.6912 - perplexity: 3.6365 - val_loss: 15.4144 - val_accuracy: 0.0826 - val_f1_m: 0.0923 - val_perplexity: 1715852319653888.0000\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.2296 - accuracy: 0.7414 - f1_m: 0.7232 - perplexity: 3.5835 - val_loss: 15.3593 - val_accuracy: 0.0826 - val_f1_m: 0.0895 - val_perplexity: 355355192197120.0000\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.2700 - accuracy: 0.7295 - f1_m: 0.6912 - perplexity: 3.8530 - val_loss: 15.3288 - val_accuracy: 0.0757 - val_f1_m: 0.0848 - val_perplexity: 2200025325109248.0000\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.1766 - accuracy: 0.7568 - f1_m: 0.7324 - perplexity: 3.4490 - val_loss: 15.3839 - val_accuracy: 0.0861 - val_f1_m: 0.0821 - val_perplexity: 278106833158144.0000\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.2462 - accuracy: 0.7395 - f1_m: 0.7122 - perplexity: 3.8491 - val_loss: 15.4388 - val_accuracy: 0.0878 - val_f1_m: 0.0886 - val_perplexity: 2563388685156352.0000\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.1992 - accuracy: 0.7467 - f1_m: 0.7267 - perplexity: 3.3807 - val_loss: 15.5379 - val_accuracy: 0.0861 - val_f1_m: 0.0938 - val_perplexity: 3265221774802944.0000\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.2315 - accuracy: 0.7411 - f1_m: 0.7316 - perplexity: 3.9635 - val_loss: 15.4737 - val_accuracy: 0.0878 - val_f1_m: 0.0860 - val_perplexity: 964134661259264.0000\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.1627 - accuracy: 0.7537 - f1_m: 0.7449 - perplexity: 3.4754 - val_loss: 15.4194 - val_accuracy: 0.0775 - val_f1_m: 0.0951 - val_perplexity: 649779361087488.0000\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.2095 - accuracy: 0.7253 - f1_m: 0.7249 - perplexity: 3.6153 - val_loss: 15.3387 - val_accuracy: 0.0895 - val_f1_m: 0.0916 - val_perplexity: 323560992145408.0000\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.2283 - accuracy: 0.7480 - f1_m: 0.7254 - perplexity: 3.6010 - val_loss: 15.2655 - val_accuracy: 0.0878 - val_f1_m: 0.0926 - val_perplexity: 499099728084992.0000\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.1852 - accuracy: 0.7538 - f1_m: 0.7319 - perplexity: 3.3897 - val_loss: 15.2283 - val_accuracy: 0.0809 - val_f1_m: 0.0862 - val_perplexity: 93118389026816.0000\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.1822 - accuracy: 0.7435 - f1_m: 0.7270 - perplexity: 3.4142 - val_loss: 15.4936 - val_accuracy: 0.0826 - val_f1_m: 0.0905 - val_perplexity: 1528570270711808.0000\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.1479 - accuracy: 0.7624 - f1_m: 0.7525 - perplexity: 3.3773 - val_loss: 15.5033 - val_accuracy: 0.0861 - val_f1_m: 0.0981 - val_perplexity: 838301514727424.0000\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.1711 - accuracy: 0.7515 - f1_m: 0.7444 - perplexity: 3.4069 - val_loss: 15.4888 - val_accuracy: 0.0843 - val_f1_m: 0.0851 - val_perplexity: 1823487018663936.0000\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.1597 - accuracy: 0.7495 - f1_m: 0.7510 - perplexity: 3.3227 - val_loss: 15.4683 - val_accuracy: 0.0861 - val_f1_m: 0.0868 - val_perplexity: 1172727666835456.0000\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.1400 - accuracy: 0.7672 - f1_m: 0.7355 - perplexity: 3.3110 - val_loss: 15.3769 - val_accuracy: 0.0775 - val_f1_m: 0.0916 - val_perplexity: 306515407798272.0000\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.1717 - accuracy: 0.7589 - f1_m: 0.7346 - perplexity: 3.5169 - val_loss: 15.4328 - val_accuracy: 0.0775 - val_f1_m: 0.0891 - val_perplexity: 230580654440448.0000\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.1410 - accuracy: 0.7492 - f1_m: 0.7419 - perplexity: 3.4346 - val_loss: 15.6391 - val_accuracy: 0.0775 - val_f1_m: 0.0829 - val_perplexity: 2221870065647616.0000\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.1826 - accuracy: 0.7460 - f1_m: 0.7292 - perplexity: 3.4717 - val_loss: 15.4561 - val_accuracy: 0.0878 - val_f1_m: 0.0946 - val_perplexity: 295945761718272.0000\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.1389 - accuracy: 0.7570 - f1_m: 0.7428 - perplexity: 3.1891 - val_loss: 15.5319 - val_accuracy: 0.0826 - val_f1_m: 0.0832 - val_perplexity: 1981755892432896.0000\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.1124 - accuracy: 0.7544 - f1_m: 0.7461 - perplexity: 3.0828 - val_loss: 15.6907 - val_accuracy: 0.0809 - val_f1_m: 0.0870 - val_perplexity: 2732059030192128.0000\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.0928 - accuracy: 0.7678 - f1_m: 0.7651 - perplexity: 3.2034 - val_loss: 15.4716 - val_accuracy: 0.0826 - val_f1_m: 0.0992 - val_perplexity: 922945924890624.0000\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.0965 - accuracy: 0.7872 - f1_m: 0.7717 - perplexity: 3.3013 - val_loss: 15.3596 - val_accuracy: 0.0757 - val_f1_m: 0.0911 - val_perplexity: 1192239703261184.0000\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 1.1323 - accuracy: 0.7694 - f1_m: 0.7515 - perplexity: 3.3261 - val_loss: 15.6441 - val_accuracy: 0.0740 - val_f1_m: 0.0810 - val_perplexity: 971479860641792.0000\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.1019 - accuracy: 0.7620 - f1_m: 0.7455 - perplexity: 3.1206 - val_loss: 15.6397 - val_accuracy: 0.0826 - val_f1_m: 0.0872 - val_perplexity: 2141110184968192.0000\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.0894 - accuracy: 0.7789 - f1_m: 0.7624 - perplexity: 3.1247 - val_loss: 15.7593 - val_accuracy: 0.0775 - val_f1_m: 0.0889 - val_perplexity: 3757684872445952.0000\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.0784 - accuracy: 0.7596 - f1_m: 0.7674 - perplexity: 3.1675 - val_loss: 15.5464 - val_accuracy: 0.0895 - val_f1_m: 0.0903 - val_perplexity: 241157699272704.0000\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.1273 - accuracy: 0.7523 - f1_m: 0.7612 - perplexity: 3.5529 - val_loss: 15.7045 - val_accuracy: 0.0757 - val_f1_m: 0.0898 - val_perplexity: 2528755679494144.0000\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 5s 66ms/step - loss: 1.0892 - accuracy: 0.7647 - f1_m: 0.7588 - perplexity: 3.2504 - val_loss: 15.7335 - val_accuracy: 0.0929 - val_f1_m: 0.0927 - val_perplexity: 1565616511123456.0000\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.1105 - accuracy: 0.7670 - f1_m: 0.7578 - perplexity: 3.3635 - val_loss: 15.6805 - val_accuracy: 0.0895 - val_f1_m: 0.0877 - val_perplexity: 1287571200016384.0000\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0672 - accuracy: 0.7707 - f1_m: 0.7704 - perplexity: 3.0895 - val_loss: 15.6111 - val_accuracy: 0.0757 - val_f1_m: 0.0890 - val_perplexity: 450665784541184.0000\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.1270 - accuracy: 0.7658 - f1_m: 0.7517 - perplexity: 3.4629 - val_loss: 15.7490 - val_accuracy: 0.0826 - val_f1_m: 0.0893 - val_perplexity: 3952909389660160.0000\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.0808 - accuracy: 0.7564 - f1_m: 0.7586 - perplexity: 3.1503 - val_loss: 15.7088 - val_accuracy: 0.0775 - val_f1_m: 0.0947 - val_perplexity: 227837042753536.0000\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.0765 - accuracy: 0.7807 - f1_m: 0.7556 - perplexity: 3.2897 - val_loss: 15.7419 - val_accuracy: 0.0861 - val_f1_m: 0.0879 - val_perplexity: 1152938068148224.0000\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.1117 - accuracy: 0.7708 - f1_m: 0.7587 - perplexity: 3.7568 - val_loss: 15.7784 - val_accuracy: 0.0826 - val_f1_m: 0.0837 - val_perplexity: 993045428305920.0000\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0632 - accuracy: 0.7588 - f1_m: 0.7616 - perplexity: 3.1368 - val_loss: 15.8095 - val_accuracy: 0.0740 - val_f1_m: 0.0883 - val_perplexity: 7964539572191232.0000\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.0327 - accuracy: 0.7865 - f1_m: 0.7822 - perplexity: 3.0011 - val_loss: 15.9148 - val_accuracy: 0.0809 - val_f1_m: 0.0942 - val_perplexity: 20392597063204864.0000\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.1137 - accuracy: 0.7520 - f1_m: 0.7476 - perplexity: 3.3388 - val_loss: 15.8315 - val_accuracy: 0.0775 - val_f1_m: 0.0903 - val_perplexity: 640294731120640.0000\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0929 - accuracy: 0.7624 - f1_m: 0.7732 - perplexity: 3.3218 - val_loss: 15.8371 - val_accuracy: 0.0843 - val_f1_m: 0.0863 - val_perplexity: 7143901781557248.0000\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0602 - accuracy: 0.7666 - f1_m: 0.7700 - perplexity: 3.2980 - val_loss: 15.8022 - val_accuracy: 0.0792 - val_f1_m: 0.0914 - val_perplexity: 2272141315670016.0000\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.1059 - accuracy: 0.7612 - f1_m: 0.7572 - perplexity: 3.2635 - val_loss: 15.7629 - val_accuracy: 0.0826 - val_f1_m: 0.0923 - val_perplexity: 3012566028648448.0000\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0749 - accuracy: 0.7751 - f1_m: 0.7693 - perplexity: 3.3318 - val_loss: 15.6317 - val_accuracy: 0.0861 - val_f1_m: 0.0947 - val_perplexity: 9928526648049664.0000\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0810 - accuracy: 0.7664 - f1_m: 0.7577 - perplexity: 3.1765 - val_loss: 15.9162 - val_accuracy: 0.0843 - val_f1_m: 0.0976 - val_perplexity: 2658704478437376.0000\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0521 - accuracy: 0.7821 - f1_m: 0.7726 - perplexity: 3.2805 - val_loss: 15.7926 - val_accuracy: 0.0809 - val_f1_m: 0.0893 - val_perplexity: 1728226523086848.0000\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0682 - accuracy: 0.7732 - f1_m: 0.7700 - perplexity: 3.2285 - val_loss: 15.4665 - val_accuracy: 0.0947 - val_f1_m: 0.0947 - val_perplexity: 3992271422750720.0000\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0434 - accuracy: 0.7770 - f1_m: 0.7730 - perplexity: 3.1562 - val_loss: 15.7187 - val_accuracy: 0.0843 - val_f1_m: 0.0945 - val_perplexity: 1076038087999488.0000\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0779 - accuracy: 0.7522 - f1_m: 0.7663 - perplexity: 3.0925 - val_loss: 15.9861 - val_accuracy: 0.0809 - val_f1_m: 0.0908 - val_perplexity: 16676630013411328.0000\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0430 - accuracy: 0.7732 - f1_m: 0.7805 - perplexity: 3.1988 - val_loss: 15.7447 - val_accuracy: 0.0809 - val_f1_m: 0.0873 - val_perplexity: 434855003291648.0000\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0465 - accuracy: 0.7852 - f1_m: 0.7903 - perplexity: 3.3506 - val_loss: 15.8364 - val_accuracy: 0.0792 - val_f1_m: 0.0940 - val_perplexity: 2342868421181440.0000\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0212 - accuracy: 0.7907 - f1_m: 0.7835 - perplexity: 3.2548 - val_loss: 16.0774 - val_accuracy: 0.0826 - val_f1_m: 0.0917 - val_perplexity: 53233748811972608.0000\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0317 - accuracy: 0.7697 - f1_m: 0.7733 - perplexity: 3.0746 - val_loss: 15.8494 - val_accuracy: 0.0843 - val_f1_m: 0.0911 - val_perplexity: 2956019294535680.0000\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0269 - accuracy: 0.7688 - f1_m: 0.7623 - perplexity: 2.9509 - val_loss: 15.9032 - val_accuracy: 0.0895 - val_f1_m: 0.0966 - val_perplexity: 3909488344039424.0000\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0636 - accuracy: 0.7628 - f1_m: 0.7634 - perplexity: 3.6761 - val_loss: 15.6724 - val_accuracy: 0.0809 - val_f1_m: 0.0965 - val_perplexity: 2532496596008960.0000\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.9492 - accuracy: 0.8012 - f1_m: 0.7969 - perplexity: 2.7072 - val_loss: 15.9059 - val_accuracy: 0.0757 - val_f1_m: 0.0890 - val_perplexity: 1732214534438912.0000\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.9988 - accuracy: 0.7863 - f1_m: 0.7863 - perplexity: 3.0342 - val_loss: 15.8230 - val_accuracy: 0.0895 - val_f1_m: 0.0926 - val_perplexity: 12290442980753408.0000\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0142 - accuracy: 0.7892 - f1_m: 0.7911 - perplexity: 3.0996 - val_loss: 15.7081 - val_accuracy: 0.0775 - val_f1_m: 0.0948 - val_perplexity: 665530549665792.0000\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0184 - accuracy: 0.7849 - f1_m: 0.7864 - perplexity: 3.0509 - val_loss: 15.7442 - val_accuracy: 0.0895 - val_f1_m: 0.0981 - val_perplexity: 885161285648384.0000\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 5s 67ms/step - loss: 1.0226 - accuracy: 0.7768 - f1_m: 0.7889 - perplexity: 3.1091 - val_loss: 15.8197 - val_accuracy: 0.0757 - val_f1_m: 0.0901 - val_perplexity: 1603501075464192.0000\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0289 - accuracy: 0.7844 - f1_m: 0.7773 - perplexity: 3.0975 - val_loss: 15.8832 - val_accuracy: 0.0723 - val_f1_m: 0.0854 - val_perplexity: 905162478583808.0000\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0028 - accuracy: 0.7765 - f1_m: 0.7824 - perplexity: 3.0062 - val_loss: 15.7851 - val_accuracy: 0.0843 - val_f1_m: 0.0816 - val_perplexity: 290696137277440.0000\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9881 - accuracy: 0.7924 - f1_m: 0.8028 - perplexity: 3.1479 - val_loss: 15.8773 - val_accuracy: 0.0723 - val_f1_m: 0.0853 - val_perplexity: 1254980317085696.0000\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0146 - accuracy: 0.7796 - f1_m: 0.7830 - perplexity: 3.0756 - val_loss: 15.9007 - val_accuracy: 0.0775 - val_f1_m: 0.0867 - val_perplexity: 76038193283072.0000\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0029 - accuracy: 0.7806 - f1_m: 0.7754 - perplexity: 2.9886 - val_loss: 15.8004 - val_accuracy: 0.0688 - val_f1_m: 0.0856 - val_perplexity: 230740088324096.0000\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0379 - accuracy: 0.7793 - f1_m: 0.7810 - perplexity: 3.1851 - val_loss: 15.9401 - val_accuracy: 0.0809 - val_f1_m: 0.0876 - val_perplexity: 868525736460288.0000\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0201 - accuracy: 0.7789 - f1_m: 0.7985 - perplexity: 3.2463 - val_loss: 15.8945 - val_accuracy: 0.0826 - val_f1_m: 0.0962 - val_perplexity: 675799011164160.0000\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0153 - accuracy: 0.7810 - f1_m: 0.7831 - perplexity: 3.2467 - val_loss: 15.7427 - val_accuracy: 0.0843 - val_f1_m: 0.0915 - val_perplexity: 489521548361728.0000\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9909 - accuracy: 0.7893 - f1_m: 0.8015 - perplexity: 3.1821 - val_loss: 15.6322 - val_accuracy: 0.0826 - val_f1_m: 0.0938 - val_perplexity: 3223581529997312.0000\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 5s 70ms/step - loss: 0.9932 - accuracy: 0.7877 - f1_m: 0.8006 - perplexity: 4.1214 - val_loss: 15.7591 - val_accuracy: 0.0912 - val_f1_m: 0.0950 - val_perplexity: 3694896745545728.0000\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 1.0083 - accuracy: 0.7906 - f1_m: 0.7858 - perplexity: 3.2831 - val_loss: 15.9339 - val_accuracy: 0.0964 - val_f1_m: 0.0989 - val_perplexity: 5289958210273280.0000\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9923 - accuracy: 0.7929 - f1_m: 0.7963 - perplexity: 3.2907 - val_loss: 15.7957 - val_accuracy: 0.0826 - val_f1_m: 0.1000 - val_perplexity: 21331691662475264.0000\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.9981 - accuracy: 0.7756 - f1_m: 0.7769 - perplexity: 3.1988 - val_loss: 16.0053 - val_accuracy: 0.0792 - val_f1_m: 0.0962 - val_perplexity: 1073718067462144.0000\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9646 - accuracy: 0.7865 - f1_m: 0.7936 - perplexity: 3.0597 - val_loss: 15.8728 - val_accuracy: 0.0861 - val_f1_m: 0.0924 - val_perplexity: 641533963403264.0000\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0269 - accuracy: 0.7694 - f1_m: 0.7793 - perplexity: 3.1470 - val_loss: 15.9198 - val_accuracy: 0.0809 - val_f1_m: 0.0903 - val_perplexity: 33861427672383488.0000\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9474 - accuracy: 0.7867 - f1_m: 0.8014 - perplexity: 2.9727 - val_loss: 15.8800 - val_accuracy: 0.0757 - val_f1_m: 0.0905 - val_perplexity: 1407288178900992.0000\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 5s 70ms/step - loss: 0.9488 - accuracy: 0.7944 - f1_m: 0.7930 - perplexity: 3.0071 - val_loss: 15.7110 - val_accuracy: 0.0843 - val_f1_m: 0.0874 - val_perplexity: 183157622046720.0000\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9573 - accuracy: 0.7902 - f1_m: 0.7969 - perplexity: 2.9047 - val_loss: 15.7057 - val_accuracy: 0.0792 - val_f1_m: 0.0910 - val_perplexity: 53855890964480.0000\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.9294 - accuracy: 0.8023 - f1_m: 0.8162 - perplexity: 2.8554 - val_loss: 15.8763 - val_accuracy: 0.0792 - val_f1_m: 0.0912 - val_perplexity: 515176595980288.0000\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9186 - accuracy: 0.8052 - f1_m: 0.8123 - perplexity: 2.8947 - val_loss: 15.7231 - val_accuracy: 0.0757 - val_f1_m: 0.0866 - val_perplexity: 701226559733760.0000\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.9319 - accuracy: 0.7884 - f1_m: 0.8045 - perplexity: 2.8530 - val_loss: 15.9375 - val_accuracy: 0.0775 - val_f1_m: 0.0880 - val_perplexity: 295910294683648.0000\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.9545 - accuracy: 0.7991 - f1_m: 0.8128 - perplexity: 3.0460 - val_loss: 16.0570 - val_accuracy: 0.0757 - val_f1_m: 0.0893 - val_perplexity: 3301861603934208.0000\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9476 - accuracy: 0.7965 - f1_m: 0.8071 - perplexity: 3.1709 - val_loss: 15.8739 - val_accuracy: 0.0775 - val_f1_m: 0.0911 - val_perplexity: 408443269677056.0000\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9769 - accuracy: 0.7842 - f1_m: 0.7889 - perplexity: 3.1673 - val_loss: 15.8210 - val_accuracy: 0.0809 - val_f1_m: 0.0848 - val_perplexity: 2391731190366208.0000\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9190 - accuracy: 0.7939 - f1_m: 0.8058 - perplexity: 2.8801 - val_loss: 16.0753 - val_accuracy: 0.0861 - val_f1_m: 0.0996 - val_perplexity: 12423796346585088.0000\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0163 - accuracy: 0.7785 - f1_m: 0.7727 - perplexity: 3.1539 - val_loss: 15.8195 - val_accuracy: 0.0861 - val_f1_m: 0.0956 - val_perplexity: 1435000918507520.0000\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.9945 - accuracy: 0.7858 - f1_m: 0.7935 - perplexity: 3.9757 - val_loss: 15.6970 - val_accuracy: 0.0809 - val_f1_m: 0.0912 - val_perplexity: 746125812301824.0000\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9268 - accuracy: 0.8053 - f1_m: 0.8111 - perplexity: 2.9613 - val_loss: 15.8026 - val_accuracy: 0.0861 - val_f1_m: 0.0942 - val_perplexity: 1795293779591168.0000\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 1.0079 - accuracy: 0.7845 - f1_m: 0.7825 - perplexity: 3.2113 - val_loss: 15.9641 - val_accuracy: 0.0740 - val_f1_m: 0.0898 - val_perplexity: 228365273399296.0000\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9791 - accuracy: 0.7754 - f1_m: 0.7913 - perplexity: 3.0090 - val_loss: 15.9844 - val_accuracy: 0.0878 - val_f1_m: 0.0947 - val_perplexity: 3341676487639040.0000\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9450 - accuracy: 0.7931 - f1_m: 0.8170 - perplexity: 3.1515 - val_loss: 15.7958 - val_accuracy: 0.0843 - val_f1_m: 0.0952 - val_perplexity: 606530248376320.0000\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9345 - accuracy: 0.7883 - f1_m: 0.8009 - perplexity: 2.8966 - val_loss: 15.8980 - val_accuracy: 0.0706 - val_f1_m: 0.0890 - val_perplexity: 1178175832850432.0000\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 5s 71ms/step - loss: 0.9577 - accuracy: 0.7846 - f1_m: 0.8006 - perplexity: 2.9766 - val_loss: 16.0307 - val_accuracy: 0.0792 - val_f1_m: 0.0846 - val_perplexity: 2584948615675904.0000\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9384 - accuracy: 0.7907 - f1_m: 0.8057 - perplexity: 2.9484 - val_loss: 16.0361 - val_accuracy: 0.0826 - val_f1_m: 0.0845 - val_perplexity: 18120198586368000.0000\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9098 - accuracy: 0.8054 - f1_m: 0.8182 - perplexity: 2.9374 - val_loss: 15.7847 - val_accuracy: 0.0843 - val_f1_m: 0.0978 - val_perplexity: 3591364411392000.0000\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9016 - accuracy: 0.8145 - f1_m: 0.8262 - perplexity: 3.3413 - val_loss: 15.6860 - val_accuracy: 0.0826 - val_f1_m: 0.0889 - val_perplexity: 221751040540672.0000\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9111 - accuracy: 0.8002 - f1_m: 0.8200 - perplexity: 2.9588 - val_loss: 15.8607 - val_accuracy: 0.0878 - val_f1_m: 0.0896 - val_perplexity: 3090031400976384.0000\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9029 - accuracy: 0.8108 - f1_m: 0.8259 - perplexity: 2.9331 - val_loss: 16.0270 - val_accuracy: 0.0947 - val_f1_m: 0.0948 - val_perplexity: 6512822372532224.0000\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9491 - accuracy: 0.7891 - f1_m: 0.8191 - perplexity: 3.2879 - val_loss: 16.0275 - val_accuracy: 0.0912 - val_f1_m: 0.0926 - val_perplexity: 2754254079000576.0000\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.8918 - accuracy: 0.8120 - f1_m: 0.8171 - perplexity: 2.9537 - val_loss: 15.8607 - val_accuracy: 0.0895 - val_f1_m: 0.0891 - val_perplexity: 1537398844424192.0000\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9328 - accuracy: 0.7890 - f1_m: 0.8045 - perplexity: 3.0086 - val_loss: 15.9125 - val_accuracy: 0.0861 - val_f1_m: 0.1018 - val_perplexity: 4949457498013696.0000\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 5s 71ms/step - loss: 0.8710 - accuracy: 0.8122 - f1_m: 0.8214 - perplexity: 2.7341 - val_loss: 15.9510 - val_accuracy: 0.0826 - val_f1_m: 0.0910 - val_perplexity: 6518504077393920.0000\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.8690 - accuracy: 0.8148 - f1_m: 0.8216 - perplexity: 2.6207 - val_loss: 15.9939 - val_accuracy: 0.0878 - val_f1_m: 0.0916 - val_perplexity: 2922295211327488.0000\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.8959 - accuracy: 0.8043 - f1_m: 0.8093 - perplexity: 2.9657 - val_loss: 16.2973 - val_accuracy: 0.0775 - val_f1_m: 0.0842 - val_perplexity: 1828918541680640.0000\n",
      "Epoch 287/300\n",
      "73/73 [==============================] - 5s 70ms/step - loss: 0.9117 - accuracy: 0.7974 - f1_m: 0.7975 - perplexity: 2.9225 - val_loss: 16.2249 - val_accuracy: 0.0878 - val_f1_m: 0.0942 - val_perplexity: 18761834488135680.0000\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 5s 71ms/step - loss: 0.8673 - accuracy: 0.8156 - f1_m: 0.8162 - perplexity: 2.8802 - val_loss: 15.9834 - val_accuracy: 0.0861 - val_f1_m: 0.1002 - val_perplexity: 3249629969776640.0000\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9359 - accuracy: 0.8004 - f1_m: 0.8069 - perplexity: 2.9936 - val_loss: 15.9374 - val_accuracy: 0.0861 - val_f1_m: 0.0963 - val_perplexity: 432535385407488.0000\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 5s 70ms/step - loss: 0.9000 - accuracy: 0.7903 - f1_m: 0.8031 - perplexity: 2.8314 - val_loss: 16.0500 - val_accuracy: 0.0861 - val_f1_m: 0.0909 - val_perplexity: 665694496620544.0000\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 5s 70ms/step - loss: 0.8828 - accuracy: 0.8094 - f1_m: 0.8202 - perplexity: 2.7617 - val_loss: 16.1445 - val_accuracy: 0.0861 - val_f1_m: 0.0957 - val_perplexity: 2507697991712768.0000\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9010 - accuracy: 0.7997 - f1_m: 0.8098 - perplexity: 2.8849 - val_loss: 16.1894 - val_accuracy: 0.0895 - val_f1_m: 0.0983 - val_perplexity: 4622787117318144.0000\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.9063 - accuracy: 0.7874 - f1_m: 0.8126 - perplexity: 2.9638 - val_loss: 16.1689 - val_accuracy: 0.0861 - val_f1_m: 0.0830 - val_perplexity: 3573437754769408.0000\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 5s 70ms/step - loss: 0.9013 - accuracy: 0.8082 - f1_m: 0.8197 - perplexity: 2.9488 - val_loss: 16.1091 - val_accuracy: 0.0895 - val_f1_m: 0.0957 - val_perplexity: 4263336472477696.0000\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.8956 - accuracy: 0.8049 - f1_m: 0.8136 - perplexity: 2.9075 - val_loss: 15.9814 - val_accuracy: 0.0792 - val_f1_m: 0.0923 - val_perplexity: 1862159441068032.0000\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 5s 70ms/step - loss: 0.9313 - accuracy: 0.7940 - f1_m: 0.8003 - perplexity: 2.9083 - val_loss: 15.8972 - val_accuracy: 0.0861 - val_f1_m: 0.0947 - val_perplexity: 2706068304035840.0000\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.8774 - accuracy: 0.8098 - f1_m: 0.8208 - perplexity: 2.9965 - val_loss: 16.0656 - val_accuracy: 0.0878 - val_f1_m: 0.0939 - val_perplexity: 45376419676553216.0000\n",
      "Epoch 298/300\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.8897 - accuracy: 0.7990 - f1_m: 0.8151 - perplexity: 2.8492 - val_loss: 15.9016 - val_accuracy: 0.0826 - val_f1_m: 0.0871 - val_perplexity: 1914446507147264.0000\n",
      "Epoch 299/300\n",
      "73/73 [==============================] - 5s 70ms/step - loss: 0.9027 - accuracy: 0.7973 - f1_m: 0.8205 - perplexity: 2.8854 - val_loss: 16.2473 - val_accuracy: 0.0723 - val_f1_m: 0.0891 - val_perplexity: 3769806075461632.0000\n",
      "Epoch 300/300\n",
      "73/73 [==============================] - 5s 70ms/step - loss: 0.8382 - accuracy: 0.8297 - f1_m: 0.8299 - perplexity: 2.7105 - val_loss: 16.1967 - val_accuracy: 0.0740 - val_f1_m: 0.0825 - val_perplexity: 4496273486905344.0000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 # minibatch \n",
    "num_epochs = 300 # nombre d'epochs\n",
    "\n",
    "\n",
    "#fit the model\n",
    "history = model.fit(predictors, label,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True,\n",
    "                 epochs=num_epochs,\n",
    "                 validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OrNqpDy5o9Np",
    "outputId": "a9812551-cbf8-46a5-f3f3-268944304db0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8deHJEAgyBpll6C4gMUAccOlQKuotS4ttlDr4Fao1XFpawdtrTgdZ/y1tnbsz6pYENs6FjcqVWdGW3XQMohBWUVkETWKgEH2NfCZP74ncAkJWe5NTu697+fjcR/33HPP8jk58D7nfs9m7o6IiGSWFnEXICIiqadwFxHJQAp3EZEMpHAXEclACncRkQykcBcRyUAKd2lWzOw/zWxsqodtrsxsopn9MQXTWWxmw1JQkmSI3LgLkPRnZlsSPrYBdgJ7os/j3f2xuk7L3c9rjGHrIwrJl4FtgAOfAHe7+yONMb9UcPcBld1mNhE42t2/HV9FEjeFuyTN3Qsqu81sFXCNu/+16nBmluvuFU1ZWxI+cfeeZmbARcBTZvaGu79T1wmk2fJKhlGzjDQaMxtmZmVm9k9m9inwiJl1NLPnzGydmX0edfdMGOdVM7sm6r7CzF43s3uiYd83s/MaOGyRmc00s81m9lczu78uzSEe/Bn4HOhvZi3MbIKZrTCzcjN7wsw6RfPoY2ZuZleb2YfAywn9xpnZJ2a22sx+eIi/2almNsvMNpjZ/MqmFjMbamafmVmv6POJ0XIeF31eZWZfNrNzgduAb5rZlmgal5rZ3Crz+b6ZPVvb8kv6UrhLY+sKdAKOBMYR/s09En3uDWwH/v8hxj8FWAp0AX4OTI72pus77H8Ac4DOwETg8roUH4X5JUAHYCHwj8DFwBeB7oTQv7/KaF8EjgdGJvQbDvQDzgH+ycy+XM28egDPA/9C+Jv9EHjazArdfRbwEPComeUDfwRud/d3E6fh7v8F/Cswzd0L3P1EYAZQZGbHJwx6OfD7uvwNJD0p3KWx7QXucPed7r7d3cvd/Wl33+bum4G7CGFYkw/c/WF33wM8CnQDjqjPsGbWGzgJ+Km773L31wmBdyjdzWwD8BlwB3C5uy8Fvgv82N3L3H0nYUMxyswSmzgnuvtWd9+e0O/OqN9CwsZtTDXz/Dbwgru/4O573f0loBQ4v3K6QHvCRupjDt6oVCuqc1o0fcxsANAHeK4u40t6UrhLY1vn7jsqP5hZGzN7yMw+MLNNwEygg5nl1DD+p5Ud7r4t6iyo57DdgfUJ/QA+qqXuT9y9g7t3cvdid/9T1P9IYHrUbLIBWEI4eJy4walu2on9PohqqupI4NLKaUfTP4OwkcLddwNTgROAX3r97vr3KPCt6JfM5cATUehLhlK4S2OrGkA/AI4FTnH3w4Czov41NbWkwmqgk5m1SejXq4HT+gg4Lwr+yldrd/84YZjqQjdxfr0JZ+BUN+0/VJl2W3e/G/Y129xB2PP/pZm1qqHGg+bv7rOBXcCZwLeAP9SynJLmFO7S1NoR2tk3RAci72jsGbr7B4TmjYlm1tLMTgO+2sDJPQjcZWZHAphZoZldVIfxbo9+tQwAriQ0k1T1R+CrZjbSzHLMrHV0ULryrJ2pwGTgasIG62c1zGsN0MfMqv7//j3h+MbuqGlKMpjCXZrar4F8Qlv2bOC/mmi+lwGnAeWEA5bTCOfj19e/E9rrXzSzzYRlOKUO4/0PsBz4G3CPu79YdQB3/4hw2uVtwDrCnvwthP+nNwCHEw6iOmEDcaWZnVnNvJ6M3svN7K2E/n8gNOkkfdGUNH+mh3VINjKzacC77t6ovxzMrA/wPpAX9znv0Vk2a4HB7r4szlqk8WnPXbKCmZ1kZkdFpzaeS9hD/nPcdTWxa4E3FezZQVeoSrboCjxDOM+9DLjW3d+Ot6SmY+HKYSOcoy9ZQM0yIiIZSM0yIiIZqFk0y3Tp0sX79OkTdxkiImll7ty5n7l7YXXfNYtw79OnD6WlpXGXISKSVszsg5q+q7VZxsymmNlaM1uU0G+amc2LXqvMbF7Uv4+ZbU/47sHULIKIiNRHXfbcpxKuatt3Bzl3/2Zlt5n9EtiYMPwKdy9OVYEiIlJ/tYa7u8+MLsQ4SHRJ9DeAEaktS0REkpFsm/uZwJoqF0UUmdnbwCbgJ+7+WnUjmtk4wv296d27d5JliGS+3bt3U1ZWxo4dO2ofWDJK69at6dmzJ3l5eXUeJ9lwHwM8nvB5NdDb3cvNbAjwZzMb4O6bqo7o7pOASQAlJSU62V6kFmVlZbRr144+ffpQ8/NKJNO4O+Xl5ZSVlVFUVFTn8Rp8nnv0cIKvkXB3u+iBDOVR91xgBXBMQ+chIvvt2LGDzp07K9izjJnRuXPnev9iS+Yipi8TbrxUllBEYeVDF8ysL+GxYiuTmIeIJFCwZ6eGrPe6nAr5OPC/wLEWHnZ8dfTVaA5skoHw4IUF0amRTwHfdff19a6qjsrK4Kc/hffea6w5iIikp1rD3d3HuHs3d89z957uPjnqf4W7P1hl2KfdfUD0WLLB7v6Xxioc4NNP4Wc/g6VLG3MuIgJQXl5OcXExxcXFdO3alR49euz7vGvXrkOOW1payg033FDrPIYOHZqSWl999VXat29PcXExxx9/PHfeeWdKprtq1SpOOOGEBo07Y8YM7r77bgD+/Oc/884776Skppo0iytUG6ply/C+e3e8dYhkg86dOzNv3jwAJk6cSEFBAT/84Q/3fV9RUUFubvWRUlJSQklJSa3zmDVrVmqKBc4880yee+45tm7dSnFxMV/96lcZPHhwreMdajmSceGFF3LhhRcCIdwvuOAC+vfvn/L5VErrG4dVhnstOw0i0kiuuOIKvvvd73LKKafwox/9iDlz5nDaaacxaNAghg4dytLoZ/Wrr77KBRdcAIQNw1VXXcWwYcPo27cv9913377pFRQU7Bt+2LBhjBo1iuOOO47LLruMyjvYvvDCCxx33HEMGTKEG264Yd90a9K2bVuGDBnC8uXLWbFiBeeeey5DhgzhzDPP5N133612OSZOnMjll1/OaaedRr9+/Xj44YcPmu6ePXu45ZZbOOmkkxg4cCAPPfQQAPfeey9XXXUVAAsXLuSEE05g27ZtTJ06leuvv55Zs2YxY8YMbrnlFoqLi1mxYsUBG51ly5bVaSNUm4zYc1e4S7a56SaIdqJTprgYfv3r+o9XVlbGrFmzyMnJYdOmTbz22mvk5uby17/+ldtuu42nn376oHHeffddXnnlFTZv3syxxx7Ltddee9A53G+//TaLFy+me/funH766fz973+npKSE8ePHM3PmTIqKihgzZkyt9ZWXlzN79mxuv/12xo0bx4MPPki/fv144403+N73vsfLL7980HJMnDiRBQsWMHv2bLZu3cqgQYP4yle+csB0J0+eTPv27XnzzTfZuXMnp59+Oueccw433ngjw4YNY/r06dx111089NBDtGmz/9nsQ4cO5cILL+SCCy5g1KhRALRv35558+ZRXFzMI488wpVXXlnv9VCVwl1EknLppZeSk5MDwMaNGxk7dizLli3DzNhdQ5vpV77yFVq1akWrVq04/PDDWbNmDT179jxgmJNPPnlfv+LiYlatWkVBQQF9+/bdd773mDFjmDRpUrXzeO211xg0aBAtWrRgwoQJHHnkkcyaNYtLL7103zA7d+5/jG7icgBcdNFF5Ofnk5+fz/Dhw5kzZw7FxfvvrPLiiy+yYMECnnrqqX3LvmzZMoqKipg6dSoDBw5k/PjxnH766bX+Da+55hoeeeQRfvWrXzFt2jTmzJlT6zi1UbiLpKGG7GE3lrZt2+7rvv322xk+fDjTp09n1apVDBs2rNpxWrVqta87JyeHioqDHy9bl2EOpbLNvdKmTZvo0KHDvuMGh1oOOPj0w6qf3Z3f/OY3jBw58qBpLVu2jIKCAj755JM61fr1r3+dO++8kxEjRjBkyBA6d+5cp/EORW3uIpIyGzdupEePHgBMnTo15dM/9thjWblyJatWrQJg2rRphx4hwWGHHUZRURFPPvkkEMJ5/vz5NQ7/7LPPsmPHDsrLy3n11Vc56aSTDvh+5MiRPPDAA/t+nbz33nts3bqVjRs3csMNNzBz5kzKy8v37dknateuHZs3b973uXXr1owcOZJrr702JU0yoHAXkRT60Y9+xK233sqgQYPqvaddF/n5+fz2t7/dd1C0Xbt2tG/fvs7jP/bYY0yePJkTTzyRAQMG8Oyzz9Y47MCBAxk+fDinnnoqt99+O927dz/g+2uuuYb+/fszePBgTjjhBMaPH09FRQU333wz1113HccccwyTJ09mwoQJrF279oBxR48ezS9+8QsGDRrEihUrALjsssto0aIF55xzTj3+IjVrFs9QLSkp8YY8rKOiAvLywrnuP/lJIxQm0owsWbKE448/Pu4yYrdlyxYKCgpwd6677jr69evHzTffnNJ5VHeqZ2O755572LhxIz/72c+q/b669W9mc9292nNM07rNPScHzLTnLpJNHn74YR599FF27drFoEGDGD9+fNwlJe2SSy5hxYoV+87cSYW0Dnez0DSjcBfJHjfffHPK99SrmjhxYqNOv6rp06enfJpp3eYOoVlG4S7Zojk0o0rTa8h6T/twb9lStx+Q7NC6dWvKy8sV8Fmm8n7urVu3rtd4ad0sA2qWkezRs2dPysrKWLduXdylSBOrfBJTfSjcRdJEXl5evZ7EI9ktI5plFO4iIgdSuIuIZCCFu4hIBlK4i4hkIIW7iEgGUriLiGQghbuISAaqNdzNbIqZrTWzRQn9JprZx2Y2L3qdn/DdrWa23MyWmtnBd7FPMYW7iMjB6rLnPhU4t5r+97p7cfR6AcDM+gOjgQHROL81s5xqxk0Z3X5ARORgtYa7u88E1tdxehcBf3L3ne7+PrAcODmJ+mqlPXcRkYMl0+Z+vZktiJptOkb9egAfJQxTFvU7iJmNM7NSMytN5l4ZuiukiMjBGhruDwBHAcXAauCX9Z2Au09y9xJ3LyksLGxgGdpzFxGpToPC3d3XuPsed98LPMz+ppePgV4Jg/aM+jUahbuIyMEaFO5m1i3h4yVA5Zk0M4DRZtbKzIqAfsCc5Eo8NIW7iMjBar3lr5k9DgwDuphZGXAHMMzMigEHVgHjAdx9sZk9AbwDVADXufuexik9ULiLiBys1nB39zHV9J58iOHvAu5Kpqj6qAx39/BMVRERyZArVN1hT6P+PhARSS8ZEe6gphkRkUQKdxGRDJQx4a5bEIiI7Jcx4a49dxGR/RTuIiIZSOEuIpKB0j7c8/LCu8JdRGS/tA937bmLiBxM4S4ikoEU7iIiGUjhLiKSgRTuIiIZKO3DPT8/vG/bFm8dIiLNSdqHe8fo6a2ffx5vHSIizYnCXUQkA6V9uOfnh3Z3hbuIyH5pH+5mYe9d4S4isl/ahzso3EVEqlK4i4hkoFrD3cymmNlaM1uU0O8XZvaumS0ws+lm1iHq38fMtpvZvOj1YGMWX0nhLiJyoLrsuU8Fzq3S7yXgBHcfCLwH3Jrw3Qp3L45e301NmYemcBcROVCt4e7uM4H1Vfq96O4V0cfZQM9GqK3OOnaE9etrH05EJFukos39KuA/Ez4XmdnbZvY/ZnZmTSOZ2TgzKzWz0nXr1iVVQMeOsHEj7N2b1GRERDJGUuFuZj8GKoDHol6rgd7uPgj4PvAfZnZYdeO6+yR3L3H3ksLCwmTKoGNHcA8BLyIiSYS7mV0BXABc5u4O4O473b086p4LrACOSUGdh6SrVEVEDtSgcDezc4EfARe6+7aE/oVmlhN19wX6AStTUeihKNxFRA6UW9sAZvY4MAzoYmZlwB2Es2NaAS+ZGcDs6MyYs4B/NrPdwF7gu+7e6Ic6Fe4iIgeqNdzdfUw1vSfXMOzTwNPJFlVfnTqFd50xIyISZMQVqocfHt7Xro23DhGR5iIjwr1zZ2jRAtasibsSEZHmISPCPScHunRRuIuIVMqIcAc44giFu4hIJYW7iEgGyqhw1wFVEZEgY8L98MO15y4iUiljwv2II2DbNtiyJe5KRETil1HhDtp7FxEBhbuISEbKmHCvvEpV4S4ikkHhfuSR4X3VqljLEBFpFjIm3Lt0CTcQW7o07kpEROKXMeEOcMwxCncREciwcD/2WHjvvbirEBGJX0aF+zHHwCefwObNcVciIhKvjAr3Y48N78uWxVuHiEjcMircj4kexa12dxHJdhkV7n37hvf334+3DhGRuGVUuLdtGy5mWrky7kpEROJVp3A3sylmttbMFiX062RmL5nZsui9Y9TfzOw+M1tuZgvMbHBjFV+doiLtuYuI1HXPfSpwbpV+E4C/uXs/4G/RZ4DzgH7RaxzwQPJl1l3fvgp3EZE6hbu7zwTWV+l9EfBo1P0ocHFC/997MBvoYGbdUlFsXRQVwYcfQkVFU81RRKT5SabN/Qh3Xx11fwpE92WkB/BRwnBlUb8mUVQEe/ZAWVlTzVFEpPlJyQFVd3fA6zOOmY0zs1IzK123bl0qygD2nzGjg6oiks2SCfc1lc0t0XvlE0w/BnolDNcz6ncAd5/k7iXuXlJYWJhEGQcqKgrvancXkWyWTLjPAMZG3WOBZxP6/0N01sypwMaE5ptG16sX5OQo3EUku+XWZSAzexwYBnQxszLgDuBu4Akzuxr4APhGNPgLwPnAcmAbcGWKaz6k3NwQ8Ap3EclmdQp3dx9Tw1dfqmZYB65Lpqhk6XRIEcl2GXWFaqWiIh1QFZHslrHhvmYNbNsWdyUiIvHI2HAHPU9VRLJXRoa77g4pItkuI8P9qKPCux7aISLZKiPDvbAwvBYtqn1YEZFMlJHhDvCFL8DChXFXISISj4wO98WLYe/euCsREWl6GR3uW7fqoKqIZKeMDndQ04yIZKeMDff+/cO7wl1EslHGhntBQTjfXeEuItkoY8MddMaMiGSvjA/3Zctgx464KxERaVoZH+579sCSJXFXIiLStDI+3AEWLIi3DhGRppbR4d6vHxx2GPz973FXIiLStDI63HNzYdgwePnluCsREWlaGR3uAF/6EqxYAR98EHclIiJNJ+PDfcSI8K69dxHJJhkf7v37Q36+bv8rItklt6EjmtmxwLSEXn2BnwIdgO8A66L+t7n7Cw2uMEktWoQrVZcvj6sCEZGm1+Bwd/elQDGAmeUAHwPTgSuBe939npRUmAJHH61wF5HskqpmmS8BK9y9WR62PProcFBV93YXkWyRqnAfDTye8Pl6M1tgZlPMrGN1I5jZODMrNbPSdevWVTdIyhx9dLgFwSefNOpsRESajaTD3cxaAhcCT0a9HgCOIjTZrAZ+Wd147j7J3UvcvaSwsDDZMg6p8oHZK1Y06mxERJqNVOy5nwe85e5rANx9jbvvcfe9wMPAySmYR1KOPjq8q91dRLJFKsJ9DAlNMmbWLeG7S4DYT0Ls3RvatIH58+OuRESkaTT4bBkAM2sLnA2MT+j9czMrBhxYVeW7WOTkwCmnwKxZcVciItI0kgp3d98KdK7S7/KkKmokQ4fC3XfDli3hKU0iIpks469QrTR0aLi3+5tvxl2JiEjjy5pwP+00MIOZM+OuRESk8WVNuHfsCEOGwIsvxl2JiEjjy5pwBzj3XJg9G9avj7sSEZHGlVXhft554RYEL70UdyUiIo0rq8L95JOhSxd45pm4KxERaVxZFe65uTBmDDz7LGzYEHc1IiKNJ6vCHeDyy2HnTnjqqbgrERFpPFkX7iUlUFQEzz0XdyUiIo0n68LdDM4+G155BSoq4q5GRKRxZF24Qwj3TZtgzpy4KxERaRxZGe4jRoQ9eJ0SKSKZKivDvVOn0PaucBeRTJWV4Q6haWb2bNi4Me5KRERSL6vDfc8eePXVuCsREUm9rA33006Dtm11SqSIZKasDfdWreDrX4cnnoBt2+KuRkQktbI23AGuuiqcEql7zYhIpsnqcD/rLDjqKJgyJe5KRERSK6vD3QyuvDJcrbpyZdzViIikTtLhbmarzGyhmc0zs9KoXycze8nMlkXvHZMvtXGMHRtC/ve/j7sSEZHUSdWe+3B3L3b3kujzBOBv7t4P+Fv0uVnq2RPOOENnzYhIZmmsZpmLgEej7keBixtpPilxzjnw1luwbl3clYiIpEYqwt2BF81srpmNi/od4e6ro+5PgSOqjmRm48ys1MxK18WcqiNHgrtuRyAimSMV4X6Guw8GzgOuM7OzEr90dydsAKjSf5K7l7h7SWFhYQrKaLjBg8Pj92bMiLUMEZGUSTrc3f3j6H0tMB04GVhjZt0Aove1yc6nMeXkwOjRMH06lJfHXY2ISPKSCncza2tm7Sq7gXOARcAMYGw02Fjg2WTm0xTGjYNdu3TWjIhkhmT33I8AXjez+cAc4Hl3/y/gbuBsM1sGfDn63Kx94Qtwyinw8MOh/V1EJJ3lJjOyu68ETqymfznwpWSmHYfvfAeuuQZmzYLTT4+7GhGRhsvqK1Sr+uY3oV27sPcuIpLOFO4JCgrgW98Kd4rcsCHuakREGk7hXsV3vgPbt8Njj8VdiYhIwyncqxgyBAYN0oFVEUlvCvdqjBsH8+dDaWnclYiINIzCvRrf+ha0aQP33ht3JSIiDaNwr8Zhh8HNN8Pjj8OTT8ZdjYhI/Snca3DHHVBcDBMnxl2JiEj9KdxrkJcXLmh65x1YvDjuakRE6kfhfghf/zq0aKHTIkUk/SjcD6FrV7jgAvi3f4N77om7GhGRulO41+JPf4KvfQ0mTIB58+KuRkSkbhTutcjPh9/9LjzM49prdWGTiKQHhXsddOwI//qvMHs2PPNM3NWIiNRO4V5HY8fCgAFw/fWwalXc1YiIHJrCvY5ycmDaNNixIxxk3bYt7opERGqmcK+HAQPC7YDfeQeuvhp27467IhGR6inc6+nss+Guu8JZNKNGwZ49cVckInIwhXsD3Hor/PrXMGMG/PM/x12NiMjBFO4NdMMNcOWVIdyfey7uakREDqRwbyAzuP/+8GCPUaPCFaw6yCoizUWDw93MepnZK2b2jpktNrMbo/4TzexjM5sXvc5PXbnNS34+/Pd/h3b4W26BkpJwNo2ISNyS2XOvAH7g7v2BU4HrzKx/9N297l4cvV5IuspmrLAQ/vKXcN/3JUv0gA8RaR4aHO7uvtrd34q6NwNLgB6pKizdjBoFF10Et90G558PK1fGXZGIZLOUtLmbWR9gEPBG1Ot6M1tgZlPMrGMN44wzs1IzK123bl0qyojdH/4Q7iD5+utw1FHwxS/Czp1xVyUi2SjpcDezAuBp4CZ33wQ8ABwFFAOrgV9WN567T3L3EncvKSwsTLaMZqFdu3D3yEWL4Mc/hpkz4Qc/gOefj7syEck2SYW7meURgv0xd38GwN3XuPsed98LPAycnHyZ6aV3b/iXfwnNNPffH25XoIAXkaaUzNkyBkwGlrj7rxL6d0sY7BJgUcPLS2+PPAIvvABf+EI4J/5//zfuikQkWySz5346cDkwosppjz83s4VmtgAYDtycikLTUceOcN554YZjbdvC0KFw/PE62CoijS+3oSO6++uAVfNVRp/62BDHHw9z54ZnsU6cCMOHw5QpMGJEuBhKRCTVdIVqE+nUCf7xH+HFFyE3F7785dBcc8898OmncVcnIplG4d7EhgwJZ9M8+GA4u+aWW6Bnz3DwdcGCuKsTkUyhcI9Bfj6MHx8OsC5ZEgL+9ddh8GC4775wv3g9q1VEkqFwj9lxx4ULn5Ytg5Ej4cYbw0NBjj8efvUr2LUr7gpFJB0p3JuJTp3g2WdDm/ykSdC5c7gA6mtfC/2WL9fevIjUncK9GcnNDXeY/M534O9/h9/+NpwnP3Ik9OsHAwfCrFlxVyki6UDh3oxdey188km4jcH994f7xQ8fDmecAT/5CaxZE3eFItJcKdybua5d4cwz4XvfgzlzYNy40Dxz993Qvz/06QOHHx6+//zzuKsVkeaiwRcxSdPr3Bl+85vQvXhx2Htv0yaE/aRJoQmnT59wamXnznDuueEK2Q0boKAgNPuISHYwbwZH6UpKSry0tDTuMtLa7NmhGSc3F8rKYONG2L49nD//yith73/GDGih32oiGcPM5rp7SXXfaV8uQ5x6Krz99v7Pu3aFUywnTgz3uHn+ebj44nAufY8ecMIJ4dWuXWwli0gj0p57hnv7bejVKzz+b8qUg291cOSRcPLJcPnloQ1/165wjr2INH+H2nNXuGeZvXvhgw9g4cL9r9deC2flVGrTJoR8794h9EeMgGOOCTc5KyxU045Ic6Fwl0PavTvc62bzZujQAVasgJYtw+0RZs488OKpli1Ds85JJ4WraT/8MLTzDx4cujdtgq9+VXe7lLpZvz40DeblxV1JelKbuxxSXl64Y2V1Pv88BPzHH8OePeFg7YcfhoOzTzxR/TgjRuxv1y8vDwdzW7SAo48OF2PVFvzu4arcM86A1q0hJye55ZPmqaIi3H7jxhvDYykltbTnLg2yYkU4Q+fEE2HLlnBqZteuMG8ePPBAaNZZty4E8549+8fr1i007fTuHU7R3LIFvvGN0CzUrx907x6aie67D04/PdxB8+qrw8HhtWuhfXv46KNwuudf/gLFxeFePJJ+FiwI/37OPjtszKX+1CwjTW7vXvjss9B+/9Zboelm4cJwW4X160NAd+oUmoLmzoVWrWDnzv3jDxwY/vN37hz2/qtq0SLMo2XLcC5/Xl44ONyjBxx2WBhn4cJwgVdBQRiuX7+wAerfP2xw1q4NvwyOPjo8HWvJktC81KFDmHfLluFzok2bwvJ88YtqekrWlClhw92pU/i3or9n/alZRppcixYhWAHOOiu8Dx0abnWcyB2WLoWjjgp7+uXl4ef6iSfCc8+FJp3XXw8bgMLCcP7+EUeE4D7xxLCxmD07hPWMGQfeRbNHjzDNioqwIahJ5UZm9+7w2Wz/cYbzzw9hX1AQ7sX/u9/Bm2+G/j16hLDfsgVGjQq/RF54AcaMgb59wwYtLy+8t2oVfm3s3Qtbt4Zxtm8P7c2dOoUaCwvD8rdvH8b79FOYMCHs2Y4ZEzZ+rVuH+jALjVMAAAhqSURBVDZuhJ//PDRrXH55atZZU5s7N7yvXx8O8vfpU7/x//jHsH5vuungDcMTT+z/BZitGw3tuUvG2Lkz3H9n48aw914Z2hBC/9NPwx76+++H5qIjjgiBPHt2CO+LL4b588NxhhNPhDfegKeeCuHw2Wdh2NzcEKbPPx82YAUFYaPwwQdhPoWFIXAaomPHMO82bcLpqx98ADt2hO/y88PGoHv3sCFLvK/QwIHhWEjr1qHZq1u3sOyrVoXaevYMAbphQ/j7DBgQpr9rV6i/a9cwr3btwt+tRYswvQ0bwnBdu4aN2Pr1YfzKX0YFBeEXzJYtob733oMuXUKdeXlhvE8+CfPv1Cn0W7s2TDs3N2zo27cP033ggXCtxpo1YWO6aVPYwHbvHuaXkxP+rvn5oXv+fBg9OmwUv/99uOKKMP0WLcI8zz8/1PH44+HGewUF4buNG0Od778PJSVhx2LlynDPpi5dwt8+P3//Ad7Vq8MdWdeuDTsnENZR+/ZhXbdqFfrt3Rumv2dPWJ6OHcMyVv4abdUqDGMWjl+1aROGSXbDo2YZkSTt3RsOJLduHUKr6neLFoUwOuEEKC0NIVhREV67d4fPH30UQqNt2/DKzw8bn/Xrw3Tmzw+/YMrLw7C9esHYsfDMM2G4wsLQXNSqVWhiGjECHn44BNWAAWFDsHp1eG3YEMIqJydM7/DDwzzbtAm1rl4dlqXyF0vbtqHGyjho0yaE7OrV+/u1bLm/5s6dQwAnNqU1xE03hbufNuS5BT16hFD+4x8P/q5Dh7DxXrq0YXXl5IRXbXW1bx/mVVYW/mbbtoWAb9kybNDWrg3/PnJzw7+F1q33b7DNwrjf/nb4hdEQsYS7mZ0L/DuQA/zO3e+uaViFu0g8tm8PG4Ju3fY3GVVUhNAxC+FdXh4+5+fvb7IyC0E2Z07YiGzdGo5dbNgQNhS7d4c91G7dwp70pk0hKAsLw558RUV44tjQoaF55sMP9+8Nl5eHXxGtWoVpbNkSArNjx9C9d2+YxuDBYfglS8JGzz18l58Pp5wS9vSffjqMt21bqKlDh7BR6NUrbOT69QvTmjUrLMP27WHY7dtDjb17h+Vq3z40AbZtu/+XxZo1IbzLy8P0KpvZCgvDMpeXh18erVuHuvPywnvPnuFvsWVLGGbAALjuuoatvyYPdzPLAd4DzgbKgDeBMe7+TnXDK9xFROrvUOHeWNcangwsd/eV7r4L+BNwUSPNS0REqmiscO8BfJTwuSzqt4+ZjTOzUjMrXdfQI1AiIlKt2O4S4u6T3L3E3UsKCwvjKkNEJCM1Vrh/DPRK+Nwz6iciIk2gscL9TaCfmRWZWUtgNDCjkeYlIiJVNMoVqu5eYWbXA/9NOBVyirsvbox5iYjIwRrt9gPu/gLwQmNNX0REaqbHLoiIZKBmcfsBM1sHfJDEJLoAn6WonDhlynKAlqW50rI0Tw1dliPdvdrTDZtFuCfLzEprukornWTKcoCWpbnSsjRPjbEsapYREclACncRkQyUKeE+Ke4CUiRTlgO0LM2VlqV5SvmyZESbu4iIHChT9txFRCSBwl1EJAOldbib2blmttTMlpvZhLjrqS8zW2VmC81snpmVRv06mdlLZrYseu8Yd53VMbMpZrbWzBYl9Ku2dgvui9bTAjMbHF/lB6thWSaa2cfRuplnZucnfHdrtCxLzWxkPFUfzMx6mdkrZvaOmS02sxuj/mm3Xg6xLOm4Xlqb2Rwzmx8ty51R/yIzeyOqeVp0Hy7MrFX0eXn0fZ8Gzdjd0/JFuGfNCqAv0BKYD/SPu656LsMqoEuVfj8HJkTdE4D/F3edNdR+FjAYWFRb7cD5wH8CBpwKvBF3/XVYlonAD6sZtn/0b60VUBT9G8yJexmi2roBg6PudoSnofVPx/VyiGVJx/ViQEHUnQe8Ef29nwBGR/0fBK6Nur8HPBh1jwamNWS+6bznnqlPe7oIeDTqfhS4OMZaauTuM4H1VXrXVPtFwO89mA10MLNuTVNp7WpYlppcBPzJ3Xe6+/vAcsK/xdi5+2p3fyvq3gwsITwkJ+3WyyGWpSbNeb24u2+JPuZFLwdGAE9F/auul8r19RTwJTOz+s43ncO91qc9pQEHXjSzuWY2Lup3hLuvjro/BY6Ip7QGqan2dF1X10fNFVMSmsfSYlmin/KDCHuJab1eqiwLpOF6MbMcM5sHrAVeIvyy2ODuFdEgifXuW5bo+41A5/rOM53DPROc4e6DgfOA68zsrMQvPfwuS8tzVdO59sgDwFFAMbAa+GW85dSdmRUATwM3ufumxO/Sbb1UsyxpuV7cfY+7FxMeXHQycFxjzzOdwz3tn/bk7h9H72uB6YSVvqbyp3H0vja+CuutptrTbl25+5roP+Re4GH2/8Rv1stiZnmEMHzM3Z+JeqfleqluWdJ1vVRy9w3AK8BphGawytuuJ9a7b1mi79sD5fWdVzqHe1o/7cnM2ppZu8pu4BxgEWEZxkaDjQWejafCBqmp9hnAP0RnZ5wKbExoJmiWqrQ9X0JYNxCWZXR0RkMR0A+Y09T1VSdql50MLHH3XyV8lXbrpaZlSdP1UmhmHaLufOBswjGEV4BR0WBV10vl+hoFvBz94qqfuI8kJ3kU+nzCUfQVwI/jrqeetfclHN2fDyyurJ/QtvY3YBnwV6BT3LXWUP/jhJ/FuwnthVfXVDvhbIH7o/W0ECiJu/46LMsfoloXRP/ZuiUM/+NoWZYC58Vdf0JdZxCaXBYA86LX+em4Xg6xLOm4XgYCb0c1LwJ+GvXvS9gALQeeBFpF/VtHn5dH3/dtyHx1+wERkQyUzs0yIiJSA4W7iEgGUriLiGQghbuISAZSuIuIZCCFu4hIBlK4i4hkoP8Dk6fvV/6lJnEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "f1 = history.history[\"f1_m\"]\n",
    "perplex = history.history[\"perplexity\"]\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.figure()\n",
    "plt.plot(epochs, f1, 'b', label='Training F1')\n",
    "plt.title('Training F1')\n",
    "plt.figure()\n",
    "plt.plot(epochs, perplex, 'b', label='Training Perplexity')\n",
    "plt.title('Training Perplexity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FsRiQH7co9Nr"
   },
   "outputs": [],
   "source": [
    "def gen_proverbs(seed, n_words):\n",
    "\n",
    "  for _ in range(n_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "      if index == predicted:\n",
    "        output = word\n",
    "        break\n",
    "    seed += \" \" + output\n",
    "  return seed\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "tTdoEI2ho9Nr",
    "outputId": "c831bee0-b49c-4b4a-9278-7cfc70fadf4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' breast make a bee for pie the bell miles away'"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_proverbs(\"\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Xq9Ki-J0dgb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Proverbs(3) lstm + F1 + Perplex.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
